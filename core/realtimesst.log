2024-10-03 12:30:47.636 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2024-10-03 12:30:47.639 - RealTimeSTT: root - INFO - Initializing audio recording (creating pyAudio input stream, sample rate: 16000 buffer size: 512
2024-10-03 12:30:47.640 - RealTimeSTT: root - INFO - Initializing WebRTC voice with Sensitivity 3
2024-10-03 12:30:47.640 - RealTimeSTT: root - DEBUG - WebRTC VAD voice activity detection engine initialized successfully
2024-10-03 12:30:48.491 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg6
2024-10-03 12:30:48.492 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg6 extension.
Traceback (most recent call last):
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torch\_ops.py", line 1295, in load_library
    ctypes.CDLL(path)
  File "C:\Python312\Lib\ctypes\__init__.py", line 379, in __init__
    self._handle = _dlopen(self._name, mode)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: Could not find module 'C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\lib\libtorio_ffmpeg6.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-03 12:30:48.495 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg5
2024-10-03 12:30:48.496 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg5 extension.
Traceback (most recent call last):
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torch\_ops.py", line 1295, in load_library
    ctypes.CDLL(path)
  File "C:\Python312\Lib\ctypes\__init__.py", line 379, in __init__
    self._handle = _dlopen(self._name, mode)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: Could not find module 'C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\lib\libtorio_ffmpeg5.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-03 12:30:48.496 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg4
2024-10-03 12:30:48.496 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg4 extension.
Traceback (most recent call last):
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torch\_ops.py", line 1295, in load_library
    ctypes.CDLL(path)
  File "C:\Python312\Lib\ctypes\__init__.py", line 379, in __init__
    self._handle = _dlopen(self._name, mode)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: Could not find module 'C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\lib\libtorio_ffmpeg4.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-03 12:30:48.496 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg
2024-10-03 12:30:48.496 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg extension.
Traceback (most recent call last):
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 106, in _find_versionsed_ffmpeg_extension
    raise RuntimeError(f"FFmpeg{version} extension is not available.")
RuntimeError: FFmpeg extension is not available.
2024-10-03 12:30:48.594 - RealTimeSTT: root - DEBUG - Silero VAD voice activity detection engine initialized successfully
2024-10-03 12:30:48.594 - RealTimeSTT: root - DEBUG - Starting realtime worker
2024-10-03 12:30:48.595 - RealTimeSTT: root - DEBUG - Waiting for main transcription model to start
2024-10-03 12:30:50.795 - RealTimeSTT: root - DEBUG - Main transcription model ready
2024-10-03 12:30:50.795 - RealTimeSTT: root - DEBUG - RealtimeSTT initialization completed successfully
2024-10-03 12:30:50.795 - RealTimeSTT: root - INFO - Setting listen time
2024-10-03 12:30:50.795 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-03 12:30:50.795 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-03 12:31:01.848 - RealTimeSTT: root - INFO - voice activity detected
2024-10-03 12:31:01.848 - RealTimeSTT: root - INFO - recording started
2024-10-03 12:31:01.848 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-03 12:31:01.849 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-03 12:31:07.667 - RealTimeSTT: root - INFO - recording stopped
2024-10-03 12:31:07.668 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-03 12:31:07.669 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-03 12:31:07.669 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-03 12:31:07.670 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-03 12:31:07.690 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-03 12:31:07.728 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-03 12:31:07.860 - RealTimeSTT: root - INFO - voice activity detected
2024-10-03 12:31:07.860 - RealTimeSTT: root - INFO - recording started
2024-10-03 12:31:07.860 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'recording'
2024-10-03 12:31:08.110 - RealTimeSTT: root - INFO - State changed from 'recording' to 'inactive'
2024-10-03 12:31:08.111 - RealTimeSTT: root - DEBUG - Model tiny.en completed transcription in 0.44 seconds
2024-10-03 12:31:08.112 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a medical doctor providing consultations.'}, {'role': 'user', 'content': "\n        You are a medical doctor providing online consultations. Your task is to respond to users' health-related queries. \n        First, ask the user to provide essential details such as their name, age, specific symptoms, and duration of the issue. \n        Be mindful that the user's query may be converted from speech to text, so their input might have informal phrasing, errors, or lack punctuation. \n        After gathering these details, give a clear and thoughtful medical response based on the information provided.\n        \n\nUser Query: Hello, Doctor. I am having a..."}], 'model': 'gpt-3.5-turbo', 'max_tokens': 400, 'temperature': 0.7}}
2024-10-03 12:31:08.129 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-10-03 12:31:08.129 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-03 12:31:08.268 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000028B5B387C20>
2024-10-03 12:31:08.268 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000028B5468FD50> server_hostname='api.openai.com' timeout=5.0
2024-10-03 12:31:08.360 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000028B5B387FB0>
2024-10-03 12:31:08.360 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-03 12:31:08.361 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-03 12:31:08.361 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-03 12:31:08.361 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-03 12:31:08.361 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-03 12:31:09.627 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 03 Oct 2024 12:31:09 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-b5vxdkodkzmlsdtxmmvcdsca'), (b'openai-processing-ms', b'755'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'9999439'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'3ms'), (b'x-request-id', b'req_09a20735f5f5b24cf28b8ce8c5a4bee3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=_Gj3N1YwFG2i6XhkuTsPRhn79qKTpjp.FH4Nl.jiCEw-1727958669-1.0.1.1-IydF0lhNDTUl8uWWlbm4ykvZSm7csKl9e9IzVXpIJkc5ML_6wWoMnBUlBSGzQn456L0PUb5KWRbo3Xa63fp2fw; path=/; expires=Thu, 03-Oct-24 13:01:09 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=G3AJhPtICVbxtS8_idPJ92TyAYBx5e1O6OFEUu8ARmo-1727958669527-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cccf28d2cd19cd6-SIN'), (b'Content-Encoding', b'gzip')])
2024-10-03 12:31:09.628 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-03 12:31:09.628 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-03 12:31:09.628 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-03 12:31:09.628 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-03 12:31:09.628 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-03 12:31:09.628 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 03 Oct 2024 12:31:09 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-b5vxdkodkzmlsdtxmmvcdsca'), ('openai-processing-ms', '755'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '10000000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '9999439'), ('x-ratelimit-reset-requests', '6ms'), ('x-ratelimit-reset-tokens', '3ms'), ('x-request-id', 'req_09a20735f5f5b24cf28b8ce8c5a4bee3'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=_Gj3N1YwFG2i6XhkuTsPRhn79qKTpjp.FH4Nl.jiCEw-1727958669-1.0.1.1-IydF0lhNDTUl8uWWlbm4ykvZSm7csKl9e9IzVXpIJkc5ML_6wWoMnBUlBSGzQn456L0PUb5KWRbo3Xa63fp2fw; path=/; expires=Thu, 03-Oct-24 13:01:09 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=G3AJhPtICVbxtS8_idPJ92TyAYBx5e1O6OFEUu8ARmo-1727958669527-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8cccf28d2cd19cd6-SIN'), ('content-encoding', 'gzip')])
2024-10-03 12:31:09.628 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_09a20735f5f5b24cf28b8ce8c5a4bee3
2024-10-03 12:31:09.629 - RealTimeSTT: root - INFO - Setting listen time
2024-10-03 12:31:09.630 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-03 12:31:10.674 - RealTimeSTT: root - INFO - recording stopped
2024-10-03 12:31:10.674 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-03 12:31:10.674 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-03 12:31:10.674 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-03 12:31:10.674 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-03 12:31:10.687 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-03 12:31:10.735 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-03 12:31:10.860 - RealTimeSTT: root - DEBUG - Model tiny.en completed transcription in 0.18 seconds
2024-10-03 12:31:10.861 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a medical doctor providing consultations.'}, {'role': 'user', 'content': "\n        You are a medical doctor providing online consultations. Your task is to respond to users' health-related queries. \n        First, ask the user to provide essential details such as their name, age, specific symptoms, and duration of the issue. \n        Be mindful that the user's query may be converted from speech to text, so their input might have informal phrasing, errors, or lack punctuation. \n        After gathering these details, give a clear and thoughtful medical response based on the information provided.\n        \n\nUser Query: Lot of headache from a past few days."}], 'model': 'gpt-3.5-turbo', 'max_tokens': 400, 'temperature': 0.7}}
2024-10-03 12:31:10.861 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-10-03 12:31:10.861 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-03 12:31:10.861 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-03 12:31:10.861 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-03 12:31:10.862 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-03 12:31:10.862 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-03 12:31:12.609 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 03 Oct 2024 12:31:12 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-b5vxdkodkzmlsdtxmmvcdsca'), (b'openai-processing-ms', b'1251'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'9999439'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'3ms'), (b'x-request-id', b'req_61b0ff1a5b1083940fddc1b82f81ade6'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cccf29ccb5b9cd6-SIN'), (b'Content-Encoding', b'gzip')])
2024-10-03 12:31:12.610 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-03 12:31:12.610 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-03 12:31:12.610 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-03 12:31:12.610 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-03 12:31:12.610 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-03 12:31:12.610 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 03 Oct 2024 12:31:12 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-b5vxdkodkzmlsdtxmmvcdsca', 'openai-processing-ms': '1251', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '10000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '9999439', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '3ms', 'x-request-id': 'req_61b0ff1a5b1083940fddc1b82f81ade6', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cccf29ccb5b9cd6-SIN', 'content-encoding': 'gzip'})
2024-10-03 12:31:12.610 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_61b0ff1a5b1083940fddc1b82f81ade6
2024-10-03 12:31:12.610 - RealTimeSTT: root - INFO - Setting listen time
2024-10-03 12:31:12.610 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-03 12:31:12.610 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-03 12:31:19.694 - RealTimeSTT: root - INFO - voice activity detected
2024-10-03 12:31:19.694 - RealTimeSTT: root - INFO - recording started
2024-10-03 12:31:19.694 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-03 12:31:19.696 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-03 12:31:21.046 - RealTimeSTT: root - INFO - recording stopped
2024-10-03 12:31:21.046 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-03 12:31:21.046 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-03 12:31:21.046 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-03 12:31:21.046 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-03 12:31:21.046 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-03 12:31:21.047 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-03 12:31:21.397 - RealTimeSTT: root - DEBUG - Model tiny.en completed transcription in 0.35 seconds
2024-10-03 12:31:21.399 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a medical doctor providing consultations.'}, {'role': 'user', 'content': "\n        You are a medical doctor providing online consultations. Your task is to respond to users' health-related queries. \n        First, ask the user to provide essential details such as their name, age, specific symptoms, and duration of the issue. \n        Be mindful that the user's query may be converted from speech to text, so their input might have informal phrasing, errors, or lack punctuation. \n        After gathering these details, give a clear and thoughtful medical response based on the information provided.\n        \n\nUser Query: Mr. Leo, yeah."}], 'model': 'gpt-3.5-turbo', 'max_tokens': 400, 'temperature': 0.7}}
2024-10-03 12:31:21.399 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-10-03 12:31:21.399 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-03 12:31:21.399 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-03 12:31:21.399 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-03 12:31:21.503 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.failed exception=KeyboardInterrupt()
2024-10-03 12:31:27.375 - RealTimeSTT: root - INFO - voice activity detected
2024-10-03 12:31:27.375 - RealTimeSTT: root - INFO - recording started
2024-10-03 12:31:27.375 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'recording'
2024-10-03 12:32:54.476 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2024-10-03 12:32:54.478 - RealTimeSTT: root - INFO - Initializing audio recording (creating pyAudio input stream, sample rate: 16000 buffer size: 512
2024-10-03 12:32:54.481 - RealTimeSTT: root - INFO - Initializing WebRTC voice with Sensitivity 3
2024-10-03 12:32:54.481 - RealTimeSTT: root - DEBUG - WebRTC VAD voice activity detection engine initialized successfully
2024-10-03 12:32:55.315 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg6
2024-10-03 12:32:55.316 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg6 extension.
Traceback (most recent call last):
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torch\_ops.py", line 1295, in load_library
    ctypes.CDLL(path)
  File "C:\Python312\Lib\ctypes\__init__.py", line 379, in __init__
    self._handle = _dlopen(self._name, mode)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: Could not find module 'C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\lib\libtorio_ffmpeg6.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-03 12:32:55.317 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg5
2024-10-03 12:32:55.317 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg5 extension.
Traceback (most recent call last):
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torch\_ops.py", line 1295, in load_library
    ctypes.CDLL(path)
  File "C:\Python312\Lib\ctypes\__init__.py", line 379, in __init__
    self._handle = _dlopen(self._name, mode)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: Could not find module 'C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\lib\libtorio_ffmpeg5.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-03 12:32:55.317 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg4
2024-10-03 12:32:55.318 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg4 extension.
Traceback (most recent call last):
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torch\_ops.py", line 1295, in load_library
    ctypes.CDLL(path)
  File "C:\Python312\Lib\ctypes\__init__.py", line 379, in __init__
    self._handle = _dlopen(self._name, mode)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: Could not find module 'C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\lib\libtorio_ffmpeg4.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-03 12:32:55.318 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg
2024-10-03 12:32:55.318 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg extension.
Traceback (most recent call last):
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 106, in _find_versionsed_ffmpeg_extension
    raise RuntimeError(f"FFmpeg{version} extension is not available.")
RuntimeError: FFmpeg extension is not available.
2024-10-03 12:32:55.420 - RealTimeSTT: root - DEBUG - Silero VAD voice activity detection engine initialized successfully
2024-10-03 12:32:55.420 - RealTimeSTT: root - DEBUG - Starting realtime worker
2024-10-03 12:32:55.421 - RealTimeSTT: root - DEBUG - Waiting for main transcription model to start
2024-10-03 12:32:57.405 - RealTimeSTT: root - DEBUG - Main transcription model ready
2024-10-03 12:32:57.406 - RealTimeSTT: root - DEBUG - RealtimeSTT initialization completed successfully
2024-10-03 12:32:57.406 - RealTimeSTT: root - INFO - Setting listen time
2024-10-03 12:32:57.406 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-03 12:32:57.406 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-03 12:32:58.357 - RealTimeSTT: root - INFO - voice activity detected
2024-10-03 12:32:58.357 - RealTimeSTT: root - INFO - recording started
2024-10-03 12:32:58.357 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-03 12:32:58.357 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-03 12:33:03.477 - RealTimeSTT: root - INFO - recording stopped
2024-10-03 12:33:03.477 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-03 12:33:03.478 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-03 12:33:03.478 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-03 12:33:03.478 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-03 12:33:03.478 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-03 12:33:03.537 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-03 12:33:03.858 - RealTimeSTT: root - DEBUG - Model tiny.en completed transcription in 0.38 seconds
2024-10-03 12:33:03.860 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a medical doctor providing consultations.'}, {'role': 'user', 'content': "\n        You are a medical doctor providing online consultations. Your task is to respond to users' health-related queries. \n        First, ask the user to provide essential details such as their name, age, specific symptoms, and duration of the issue. \n        Be mindful that the user's query may be converted from speech to text, so their input might have informal phrasing, errors, or lack punctuation. \n        After gathering these details, give a clear and thoughtful medical response based on the information provided.\n        \n\nUser Query: Hello doctor, I am having a lot of headache since 5 days."}], 'model': 'gpt-3.5-turbo', 'max_tokens': 400, 'temperature': 0.7}}
2024-10-03 12:33:03.878 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-10-03 12:33:03.878 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-03 12:33:04.099 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B813527B60>
2024-10-03 12:33:04.099 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001B80C80FB50> server_hostname='api.openai.com' timeout=5.0
2024-10-03 12:33:04.211 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B80C8696D0>
2024-10-03 12:33:04.211 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-03 12:33:04.211 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-03 12:33:04.211 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-03 12:33:04.211 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-03 12:33:04.211 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-03 12:33:06.422 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 03 Oct 2024 12:33:06 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-b5vxdkodkzmlsdtxmmvcdsca'), (b'openai-processing-ms', b'1597'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'9999434'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'3ms'), (b'x-request-id', b'req_30e48784827d6147f456195fdab2bb3b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=GlwsjW.dCbw3jE5evH5ewKlfjixMnU.Hi.cdlsowZMc-1727958786-1.0.1.1-cm2pIJoC9OyZlnB.cqDSiu.7hdl74uxDbI.xzz9guzy9sef1jpSPrT8numq8tesrozXnVfrVv0wDmn5IBp89hA; path=/; expires=Thu, 03-Oct-24 13:03:06 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=VUGlryeBd9A.SOdP4RJ6D4Q55suMuDo.MU8Zw6uLT_k-1727958786242-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cccf561087ac601-KHI'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-03 12:33:06.422 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-03 12:33:06.422 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-03 12:33:06.426 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-03 12:33:06.426 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-03 12:33:06.426 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-03 12:33:06.427 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 03 Oct 2024 12:33:06 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-b5vxdkodkzmlsdtxmmvcdsca'), ('openai-processing-ms', '1597'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '10000000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '9999434'), ('x-ratelimit-reset-requests', '6ms'), ('x-ratelimit-reset-tokens', '3ms'), ('x-request-id', 'req_30e48784827d6147f456195fdab2bb3b'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=GlwsjW.dCbw3jE5evH5ewKlfjixMnU.Hi.cdlsowZMc-1727958786-1.0.1.1-cm2pIJoC9OyZlnB.cqDSiu.7hdl74uxDbI.xzz9guzy9sef1jpSPrT8numq8tesrozXnVfrVv0wDmn5IBp89hA; path=/; expires=Thu, 03-Oct-24 13:03:06 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=VUGlryeBd9A.SOdP4RJ6D4Q55suMuDo.MU8Zw6uLT_k-1727958786242-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8cccf561087ac601-KHI'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2024-10-03 12:33:06.427 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_30e48784827d6147f456195fdab2bb3b
2024-10-03 12:33:06.430 - RealTimeSTT: root - INFO - Setting listen time
2024-10-03 12:33:06.430 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-03 12:33:06.430 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-03 12:33:10.008 - RealTimeSTT: root - INFO - voice activity detected
2024-10-03 12:33:10.008 - RealTimeSTT: root - INFO - recording started
2024-10-03 12:33:10.009 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-03 12:33:10.009 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-03 12:33:14.874 - RealTimeSTT: root - INFO - recording stopped
2024-10-03 12:33:14.874 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-03 12:33:14.874 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-03 12:33:14.874 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-03 12:33:14.874 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-03 12:33:14.890 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-03 12:33:14.935 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-03 12:33:15.057 - RealTimeSTT: root - INFO - voice activity detected
2024-10-03 12:33:15.057 - RealTimeSTT: root - INFO - recording started
2024-10-03 12:33:15.057 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'recording'
2024-10-03 12:33:15.081 - RealTimeSTT: root - INFO - State changed from 'recording' to 'inactive'
2024-10-03 12:33:15.081 - RealTimeSTT: root - DEBUG - Model tiny.en completed transcription in 0.21 seconds
2024-10-03 12:33:15.083 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a medical doctor providing consultations.'}, {'role': 'user', 'content': "\n        You are a medical doctor providing online consultations. Your task is to respond to users' health-related queries. \n        First, ask the user to provide essential details such as their name, age, specific symptoms, and duration of the issue. \n        Be mindful that the user's query may be converted from speech to text, so their input might have informal phrasing, errors, or lack punctuation. \n        After gathering these details, give a clear and thoughtful medical response based on the information provided.\n        \n\nUser Query: Ah yeah my name is John and I am 25 years old."}], 'model': 'gpt-3.5-turbo', 'max_tokens': 400, 'temperature': 0.7}}
2024-10-03 12:33:15.083 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-10-03 12:33:15.083 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-03 12:33:15.083 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-03 12:33:15.083 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-03 12:33:15.310 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B81354CEC0>
2024-10-03 12:33:15.310 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001B80C80FB50> server_hostname='api.openai.com' timeout=5.0
2024-10-03 12:33:15.422 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B80B58FAD0>
2024-10-03 12:33:15.422 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-03 12:33:15.422 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-03 12:33:15.422 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-03 12:33:15.422 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-03 12:33:15.422 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-03 12:33:16.413 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 03 Oct 2024 12:33:16 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-b5vxdkodkzmlsdtxmmvcdsca'), (b'openai-processing-ms', b'451'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'9999437'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'3ms'), (b'x-request-id', b'req_7fe6c429371fca2e34e85a2dcebeebb8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cccf5a718e8285b-KHI'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-03 12:33:16.413 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-03 12:33:16.413 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-03 12:33:16.413 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-03 12:33:16.413 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-03 12:33:16.413 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-03 12:33:16.413 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 03 Oct 2024 12:33:16 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-b5vxdkodkzmlsdtxmmvcdsca', 'openai-processing-ms': '451', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '10000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '9999437', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '3ms', 'x-request-id': 'req_7fe6c429371fca2e34e85a2dcebeebb8', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cccf5a718e8285b-KHI', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-03 12:33:16.413 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_7fe6c429371fca2e34e85a2dcebeebb8
2024-10-03 12:33:16.414 - RealTimeSTT: root - INFO - Setting listen time
2024-10-03 12:33:16.414 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-03 12:33:21.589 - RealTimeSTT: root - INFO - recording stopped
2024-10-03 12:33:21.589 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-03 12:33:21.589 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-03 12:33:21.589 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-03 12:33:21.589 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-03 12:33:21.589 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-03 12:33:21.650 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-03 12:33:21.827 - RealTimeSTT: root - DEBUG - Model tiny.en completed transcription in 0.24 seconds
2024-10-03 12:33:21.829 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a medical doctor providing consultations.'}, {'role': 'user', 'content': "\n        You are a medical doctor providing online consultations. Your task is to respond to users' health-related queries. \n        First, ask the user to provide essential details such as their name, age, specific symptoms, and duration of the issue. \n        Be mindful that the user's query may be converted from speech to text, so their input might have informal phrasing, errors, or lack punctuation. \n        After gathering these details, give a clear and thoughtful medical response based on the information provided.\n        \n\nUser Query: And I am having headache in complete head mostly on the left side of the head."}], 'model': 'gpt-3.5-turbo', 'max_tokens': 400, 'temperature': 0.7}}
2024-10-03 12:33:21.829 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-10-03 12:33:21.829 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-03 12:33:21.829 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-03 12:33:21.829 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-03 12:33:22.057 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B80C9247D0>
2024-10-03 12:33:22.057 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001B80C80FB50> server_hostname='api.openai.com' timeout=5.0
2024-10-03 12:33:22.288 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B81356CC20>
2024-10-03 12:33:22.288 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-03 12:33:22.288 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-03 12:33:22.288 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-03 12:33:22.289 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-03 12:33:22.289 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-03 12:33:24.331 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 03 Oct 2024 12:33:24 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-b5vxdkodkzmlsdtxmmvcdsca'), (b'openai-processing-ms', b'1500'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'9999428'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'3ms'), (b'x-request-id', b'req_a9cb47ec74f6e882d2f4cfb4b65d0ff6'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cccf5d2488a020a-SIN'), (b'Content-Encoding', b'gzip')])
2024-10-03 12:33:24.332 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-03 12:33:24.332 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-03 12:33:24.332 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-03 12:33:24.332 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-03 12:33:24.332 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-03 12:33:24.332 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 03 Oct 2024 12:33:24 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-b5vxdkodkzmlsdtxmmvcdsca', 'openai-processing-ms': '1500', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '10000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '9999428', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '3ms', 'x-request-id': 'req_a9cb47ec74f6e882d2f4cfb4b65d0ff6', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cccf5d2488a020a-SIN', 'content-encoding': 'gzip'})
2024-10-03 12:33:24.332 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_a9cb47ec74f6e882d2f4cfb4b65d0ff6
2024-10-03 12:33:24.333 - RealTimeSTT: root - INFO - Setting listen time
2024-10-03 12:33:24.333 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-03 12:33:24.333 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-03 12:33:34.135 - RealTimeSTT: root - INFO - voice activity detected
2024-10-03 12:33:34.135 - RealTimeSTT: root - INFO - recording started
2024-10-03 12:33:34.135 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-03 12:33:34.135 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-03 12:33:52.055 - RealTimeSTT: root - INFO - recording stopped
2024-10-03 12:33:52.055 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-03 12:33:52.057 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-03 12:33:52.057 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-03 12:33:52.058 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-03 12:33:52.077 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-03 12:33:52.117 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-03 12:33:52.496 - RealTimeSTT: root - DEBUG - Model tiny.en completed transcription in 0.44 seconds
2024-10-03 12:33:52.497 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a medical doctor providing consultations.'}, {'role': 'user', 'content': "\n        You are a medical doctor providing online consultations. Your task is to respond to users' health-related queries. \n        First, ask the user to provide essential details such as their name, age, specific symptoms, and duration of the issue. \n        Be mindful that the user's query may be converted from speech to text, so their input might have informal phrasing, errors, or lack punctuation. \n        After gathering these details, give a clear and thoughtful medical response based on the information provided.\n        \n\nUser Query: No, I haven't tried any remedies or medicine as of yet, and when I use phone or laptop, it triggers and I am experiencing this headache on the left side of my head from 5 days. My age is 25 and my name is John, please help."}], 'model': 'gpt-3.5-turbo', 'max_tokens': 400, 'temperature': 0.7}}
2024-10-03 12:33:52.498 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-10-03 12:33:52.498 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-03 12:33:52.498 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-03 12:33:52.498 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-03 12:33:52.600 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B80C946F30>
2024-10-03 12:33:52.600 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001B80C80FB50> server_hostname='api.openai.com' timeout=5.0
2024-10-03 12:33:52.669 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B81356EF30>
2024-10-03 12:33:52.669 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-03 12:33:52.669 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-03 12:33:52.669 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-03 12:33:52.669 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-03 12:33:52.669 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-03 12:33:56.487 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 03 Oct 2024 12:33:56 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-b5vxdkodkzmlsdtxmmvcdsca'), (b'openai-processing-ms', b'2985'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'9999392'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'3ms'), (b'x-request-id', b'req_da09486e1e181d42cdce78e3370c26db'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cccf68feec3c605-KHI'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-03 12:33:56.487 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-03 12:33:56.487 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-03 12:33:56.549 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-03 12:33:56.549 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-03 12:33:56.549 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-03 12:33:56.549 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 03 Oct 2024 12:33:56 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-b5vxdkodkzmlsdtxmmvcdsca', 'openai-processing-ms': '2985', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '10000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '9999392', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '3ms', 'x-request-id': 'req_da09486e1e181d42cdce78e3370c26db', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cccf68feec3c605-KHI', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-03 12:33:56.550 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_da09486e1e181d42cdce78e3370c26db
2024-10-03 12:33:56.550 - RealTimeSTT: root - INFO - Setting listen time
2024-10-03 12:33:56.550 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-03 12:33:56.550 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-03 12:34:00.690 - RealTimeSTT: root - INFO - voice activity detected
2024-10-03 12:34:00.690 - RealTimeSTT: root - INFO - recording started
2024-10-03 12:34:00.690 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-03 12:34:00.690 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-03 12:34:01.849 - RealTimeSTT: root - INFO - recording stopped
2024-10-03 12:34:01.849 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-03 12:34:01.849 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-03 12:34:01.849 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-03 12:34:01.849 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-03 12:34:01.859 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-03 12:34:01.909 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-03 12:34:02.267 - RealTimeSTT: root - DEBUG - Model tiny.en completed transcription in 0.42 seconds
2024-10-03 12:34:02.268 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a medical doctor providing consultations.'}, {'role': 'user', 'content': "\n        You are a medical doctor providing online consultations. Your task is to respond to users' health-related queries. \n        First, ask the user to provide essential details such as their name, age, specific symptoms, and duration of the issue. \n        Be mindful that the user's query may be converted from speech to text, so their input might have informal phrasing, errors, or lack punctuation. \n        After gathering these details, give a clear and thoughtful medical response based on the information provided.\n        \n\nUser Query: Galada."}], 'model': 'gpt-3.5-turbo', 'max_tokens': 400, 'temperature': 0.7}}
2024-10-03 12:34:02.268 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-10-03 12:34:02.268 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-03 12:34:02.268 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-03 12:34:02.268 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-03 12:34:02.414 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B81356D730>
2024-10-03 12:34:02.414 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001B80C80FB50> server_hostname='api.openai.com' timeout=5.0
2024-10-03 12:34:02.574 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B81356D6D0>
2024-10-03 12:34:02.574 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-03 12:34:02.574 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-03 12:34:02.574 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-03 12:34:02.574 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-03 12:34:02.574 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-03 12:34:03.916 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 03 Oct 2024 12:34:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-b5vxdkodkzmlsdtxmmvcdsca'), (b'openai-processing-ms', b'830'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'9999446'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'3ms'), (b'x-request-id', b'req_ad9be6f28d71dc6b22680f4e5b3920db'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cccf6ce0ee4ce56-SIN'), (b'Content-Encoding', b'gzip')])
2024-10-03 12:34:03.916 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-03 12:34:03.916 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-03 12:34:03.927 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-03 12:34:03.927 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-03 12:34:03.928 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-03 12:34:03.928 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 03 Oct 2024 12:34:03 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-b5vxdkodkzmlsdtxmmvcdsca', 'openai-processing-ms': '830', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '10000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '9999446', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '3ms', 'x-request-id': 'req_ad9be6f28d71dc6b22680f4e5b3920db', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cccf6ce0ee4ce56-SIN', 'content-encoding': 'gzip'})
2024-10-03 12:34:03.928 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_ad9be6f28d71dc6b22680f4e5b3920db
2024-10-03 12:34:03.928 - RealTimeSTT: root - INFO - Setting listen time
2024-10-03 12:34:03.928 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-03 12:34:03.928 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-03 12:34:05.617 - RealTimeSTT: root - INFO - voice activity detected
2024-10-03 12:34:05.617 - RealTimeSTT: root - INFO - recording started
2024-10-03 12:34:05.617 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-03 12:34:05.617 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-03 12:34:08.949 - RealTimeSTT: root - INFO - recording stopped
2024-10-03 12:34:08.949 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-03 12:34:08.950 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-03 12:34:08.950 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-03 12:34:08.950 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-03 12:34:08.950 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-03 12:34:09.009 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-03 12:34:09.116 - RealTimeSTT: root - DEBUG - Model tiny.en completed transcription in 0.17 seconds
2024-10-03 12:34:09.118 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a medical doctor providing consultations.'}, {'role': 'user', 'content': "\n        You are a medical doctor providing online consultations. Your task is to respond to users' health-related queries. \n        First, ask the user to provide essential details such as their name, age, specific symptoms, and duration of the issue. \n        Be mindful that the user's query may be converted from speech to text, so their input might have informal phrasing, errors, or lack punctuation. \n        After gathering these details, give a clear and thoughtful medical response based on the information provided.\n        \n\nUser Query: Doctor, I think I will die."}], 'model': 'gpt-3.5-turbo', 'max_tokens': 400, 'temperature': 0.7}}
2024-10-03 12:34:09.118 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-10-03 12:34:09.118 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-03 12:34:09.118 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-03 12:34:09.118 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-03 12:34:09.428 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B80C869B50>
2024-10-03 12:34:09.428 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001B80C80FB50> server_hostname='api.openai.com' timeout=5.0
2024-10-03 12:34:09.457 - RealTimeSTT: root - INFO - voice activity detected
2024-10-03 12:34:09.457 - RealTimeSTT: root - INFO - recording started
2024-10-03 12:34:09.457 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'recording'
2024-10-03 12:34:09.460 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B81354CF50>
2024-10-03 12:34:09.460 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-03 12:34:09.460 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-03 12:34:09.460 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-03 12:34:09.460 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-03 12:34:09.460 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-03 12:34:11.438 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 03 Oct 2024 12:34:11 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-b5vxdkodkzmlsdtxmmvcdsca'), (b'openai-processing-ms', b'767'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'9999440'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'3ms'), (b'x-request-id', b'req_fe083393a123807fd766b11b73ee20e8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cccf6f8dd37c60d-KHI'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-03 12:34:11.438 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-03 12:34:11.438 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-03 12:34:11.438 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-03 12:34:11.438 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-03 12:34:11.438 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-03 12:34:11.438 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 03 Oct 2024 12:34:11 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-b5vxdkodkzmlsdtxmmvcdsca', 'openai-processing-ms': '767', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '10000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '9999440', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '3ms', 'x-request-id': 'req_fe083393a123807fd766b11b73ee20e8', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cccf6f8dd37c60d-KHI', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-03 12:34:11.439 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_fe083393a123807fd766b11b73ee20e8
2024-10-03 12:34:11.439 - RealTimeSTT: root - INFO - Setting listen time
2024-10-03 12:34:11.439 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-03 12:34:12.089 - RealTimeSTT: root - INFO - recording stopped
2024-10-03 12:34:12.089 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-03 12:34:12.089 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-03 12:34:12.089 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-03 12:34:12.089 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-03 12:34:12.100 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-03 12:34:12.149 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-03 12:34:12.263 - RealTimeSTT: root - DEBUG - Model tiny.en completed transcription in 0.17 seconds
2024-10-03 12:34:12.264 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a medical doctor providing consultations.'}, {'role': 'user', 'content': "\n        You are a medical doctor providing online consultations. Your task is to respond to users' health-related queries. \n        First, ask the user to provide essential details such as their name, age, specific symptoms, and duration of the issue. \n        Be mindful that the user's query may be converted from speech to text, so their input might have informal phrasing, errors, or lack punctuation. \n        After gathering these details, give a clear and thoughtful medical response based on the information provided.\n        \n\nUser Query: I want you to do that."}], 'model': 'gpt-3.5-turbo', 'max_tokens': 400, 'temperature': 0.7}}
2024-10-03 12:34:12.264 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-10-03 12:34:12.265 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-03 12:34:12.265 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-03 12:34:12.265 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-03 12:34:12.265 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-03 12:34:12.265 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-03 12:34:12.921 - RealTimeSTT: root - INFO - voice activity detected
2024-10-03 12:34:12.921 - RealTimeSTT: root - INFO - recording started
2024-10-03 12:34:12.921 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'recording'
2024-10-03 12:34:13.503 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 03 Oct 2024 12:34:13 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-b5vxdkodkzmlsdtxmmvcdsca'), (b'openai-processing-ms', b'809'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'9999442'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'3ms'), (b'x-request-id', b'req_07a8c292c83279fc5894d14113dafd93'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cccf70a5b7dc60d-KHI'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-03 12:34:13.504 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-03 12:34:13.504 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-03 12:34:13.504 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-03 12:34:13.504 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-03 12:34:13.504 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-03 12:34:13.504 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 03 Oct 2024 12:34:13 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-b5vxdkodkzmlsdtxmmvcdsca', 'openai-processing-ms': '809', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '10000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '9999442', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '3ms', 'x-request-id': 'req_07a8c292c83279fc5894d14113dafd93', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cccf70a5b7dc60d-KHI', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-03 12:34:13.504 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_07a8c292c83279fc5894d14113dafd93
2024-10-03 12:34:13.504 - RealTimeSTT: root - INFO - Setting listen time
2024-10-03 12:34:13.504 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-03 12:34:16.569 - RealTimeSTT: root - INFO - recording stopped
2024-10-03 12:34:16.569 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-03 12:34:16.570 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-03 12:34:16.570 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-03 12:34:16.570 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-03 12:34:16.574 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-03 12:34:16.629 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-03 12:34:16.801 - RealTimeSTT: root - DEBUG - Model tiny.en completed transcription in 0.23 seconds
2024-10-03 12:34:16.802 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a medical doctor providing consultations.'}, {'role': 'user', 'content': "\n        You are a medical doctor providing online consultations. Your task is to respond to users' health-related queries. \n        First, ask the user to provide essential details such as their name, age, specific symptoms, and duration of the issue. \n        Be mindful that the user's query may be converted from speech to text, so their input might have informal phrasing, errors, or lack punctuation. \n        After gathering these details, give a clear and thoughtful medical response based on the information provided.\n        \n\nUser Query: But don't worry if I die I'll take you all with me."}], 'model': 'gpt-3.5-turbo', 'max_tokens': 400, 'temperature': 0.7}}
2024-10-03 12:34:16.803 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-10-03 12:34:16.803 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-03 12:34:16.803 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-03 12:34:16.803 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-03 12:34:16.803 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-03 12:34:16.803 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-03 12:34:18.106 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 03 Oct 2024 12:34:17 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-b5vxdkodkzmlsdtxmmvcdsca'), (b'openai-processing-ms', b'769'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'9999435'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'3ms'), (b'x-request-id', b'req_ed8774d5d3263820436992f5e5b3e72f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cccf726bc59c60d-KHI'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-03 12:34:18.106 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-03 12:34:18.106 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-03 12:34:18.106 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-03 12:34:18.106 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-03 12:34:18.106 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-03 12:34:18.106 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 03 Oct 2024 12:34:17 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-b5vxdkodkzmlsdtxmmvcdsca', 'openai-processing-ms': '769', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '10000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '9999435', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '3ms', 'x-request-id': 'req_ed8774d5d3263820436992f5e5b3e72f', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cccf726bc59c60d-KHI', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-03 12:34:18.106 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_ed8774d5d3263820436992f5e5b3e72f
2024-10-03 12:34:18.107 - RealTimeSTT: root - INFO - Setting listen time
2024-10-03 12:34:18.107 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-03 12:34:18.107 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-03 12:34:19.923 - RealTimeSTT: root - INFO - KeyboardInterrupt in wait_audio, shutting down
2024-10-03 12:34:19.923 - RealTimeSTT: root - DEBUG - Finishing recording thread
2024-10-03 12:34:19.938 - RealTimeSTT: root - DEBUG - Terminating reader process
2024-10-03 12:34:19.985 - RealTimeSTT: root - DEBUG - Receive from stdout pipe
2024-10-03 12:34:20.186 - RealTimeSTT: root - INFO - KeyboardInterrupt in text() method
2024-10-03 12:34:25.490 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-03 12:34:25.491 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-03 13:21:21.578 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2024-10-03 13:21:21.580 - RealTimeSTT: root - INFO - Initializing audio recording (creating pyAudio input stream, sample rate: 16000 buffer size: 512
2024-10-03 13:21:21.581 - RealTimeSTT: root - INFO - Initializing WebRTC voice with Sensitivity 3
2024-10-03 13:21:21.581 - RealTimeSTT: root - DEBUG - WebRTC VAD voice activity detection engine initialized successfully
2024-10-03 13:21:22.245 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg6
2024-10-03 13:21:22.246 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg6 extension.
Traceback (most recent call last):
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torch\_ops.py", line 1295, in load_library
    ctypes.CDLL(path)
  File "C:\Python312\Lib\ctypes\__init__.py", line 379, in __init__
    self._handle = _dlopen(self._name, mode)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: Could not find module 'C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\lib\libtorio_ffmpeg6.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-03 13:21:22.247 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg5
2024-10-03 13:21:22.247 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg5 extension.
Traceback (most recent call last):
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torch\_ops.py", line 1295, in load_library
    ctypes.CDLL(path)
  File "C:\Python312\Lib\ctypes\__init__.py", line 379, in __init__
    self._handle = _dlopen(self._name, mode)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: Could not find module 'C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\lib\libtorio_ffmpeg5.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-03 13:21:22.248 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg4
2024-10-03 13:21:22.248 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg4 extension.
Traceback (most recent call last):
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torch\_ops.py", line 1295, in load_library
    ctypes.CDLL(path)
  File "C:\Python312\Lib\ctypes\__init__.py", line 379, in __init__
    self._handle = _dlopen(self._name, mode)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: Could not find module 'C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\lib\libtorio_ffmpeg4.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-03 13:21:22.248 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg
2024-10-03 13:21:22.248 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg extension.
Traceback (most recent call last):
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 106, in _find_versionsed_ffmpeg_extension
    raise RuntimeError(f"FFmpeg{version} extension is not available.")
RuntimeError: FFmpeg extension is not available.
2024-10-03 13:21:22.354 - RealTimeSTT: root - DEBUG - Silero VAD voice activity detection engine initialized successfully
2024-10-03 13:21:22.355 - RealTimeSTT: root - DEBUG - Starting realtime worker
2024-10-03 13:21:22.355 - RealTimeSTT: root - DEBUG - Waiting for main transcription model to start
2024-10-03 13:21:24.501 - RealTimeSTT: root - DEBUG - Main transcription model ready
2024-10-03 13:21:24.501 - RealTimeSTT: root - DEBUG - RealtimeSTT initialization completed successfully
2024-10-03 13:21:24.501 - RealTimeSTT: root - INFO - Setting listen time
2024-10-03 13:21:24.501 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-03 13:21:24.501 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-03 13:21:26.370 - RealTimeSTT: root - INFO - voice activity detected
2024-10-03 13:21:26.370 - RealTimeSTT: root - INFO - recording started
2024-10-03 13:21:26.370 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-03 13:21:26.370 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-03 13:21:30.210 - RealTimeSTT: root - INFO - recording stopped
2024-10-03 13:21:30.210 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-03 13:21:30.211 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-03 13:21:30.211 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-03 13:21:30.211 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-03 13:21:30.221 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-03 13:21:30.281 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-03 13:21:30.380 - RealTimeSTT: root - DEBUG - Model tiny.en completed transcription in 0.17 seconds
2024-10-03 13:21:30.382 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a medical doctor providing consultations.'}, {'role': 'user', 'content': "\n        You are a medical doctor providing online consultations. Your task is to respond to users' health-related queries. \n        First, ask the user to provide essential details such as their name, age, specific symptoms, and duration of the issue. \n        Be mindful that the user's query may be converted from speech to text, so their input might have informal phrasing, errors, or lack punctuation. \n        After gathering these details, give a clear and thoughtful medical response based on the information provided.\n        \n\nUser Query: Hello, my name is John and I am calling."}], 'model': 'gpt-3.5-turbo', 'max_tokens': 400, 'temperature': 0.7}}
2024-10-03 13:21:30.397 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-10-03 13:21:30.397 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-03 13:21:30.590 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000276596FD9D0>
2024-10-03 13:21:30.590 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000276596C09D0> server_hostname='api.openai.com' timeout=5.0
2024-10-03 13:21:30.731 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000276601C62A0>
2024-10-03 13:21:30.731 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-03 13:21:30.731 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-03 13:21:30.731 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-03 13:21:30.731 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-03 13:21:30.731 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-03 13:21:31.996 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 03 Oct 2024 13:21:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-b5vxdkodkzmlsdtxmmvcdsca'), (b'openai-processing-ms', b'825'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'9999437'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'3ms'), (b'x-request-id', b'req_072f8f567f9ad5dd3a7328d5276b58eb'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=YCOqCdefynk_Uev2wwFVVyxm2RKmWjPMyjs3hbHMFKM-1727961691-1.0.1.1-SlB_zI0myJMdD9dzYXW1R71Z_xsWEwREcwMrvYtJlMEPt4o3Vp3Wx_P_oimL5G1sE81cGkyp7Mxs8LrODo4EAQ; path=/; expires=Thu, 03-Oct-24 13:51:31 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=mkklISB7xtkAU6gnYgwubsx6d_oWgTiJlJNBY5EMIf4-1727961691846-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ccd3c56fc7f9e61-CDG'), (b'Content-Encoding', b'gzip')])
2024-10-03 13:21:31.996 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-03 13:21:31.997 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-03 13:21:31.999 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-03 13:21:31.999 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-03 13:21:31.999 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-03 13:21:31.999 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 03 Oct 2024 13:21:31 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-b5vxdkodkzmlsdtxmmvcdsca'), ('openai-processing-ms', '825'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '10000000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '9999437'), ('x-ratelimit-reset-requests', '6ms'), ('x-ratelimit-reset-tokens', '3ms'), ('x-request-id', 'req_072f8f567f9ad5dd3a7328d5276b58eb'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=YCOqCdefynk_Uev2wwFVVyxm2RKmWjPMyjs3hbHMFKM-1727961691-1.0.1.1-SlB_zI0myJMdD9dzYXW1R71Z_xsWEwREcwMrvYtJlMEPt4o3Vp3Wx_P_oimL5G1sE81cGkyp7Mxs8LrODo4EAQ; path=/; expires=Thu, 03-Oct-24 13:51:31 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=mkklISB7xtkAU6gnYgwubsx6d_oWgTiJlJNBY5EMIf4-1727961691846-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8ccd3c56fc7f9e61-CDG'), ('content-encoding', 'gzip')])
2024-10-03 13:21:31.999 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_072f8f567f9ad5dd3a7328d5276b58eb
2024-10-03 13:21:32.000 - RealTimeSTT: root - INFO - Setting listen time
2024-10-03 13:21:32.000 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-03 13:21:32.000 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-03 13:21:35.654 - RealTimeSTT: root - INFO - voice activity detected
2024-10-03 13:21:35.654 - RealTimeSTT: root - INFO - recording started
2024-10-03 13:21:35.654 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-03 13:21:35.656 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-03 13:21:40.134 - RealTimeSTT: root - INFO - recording stopped
2024-10-03 13:21:40.134 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-03 13:21:40.135 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-03 13:21:40.135 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-03 13:21:40.135 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-03 13:21:40.143 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-03 13:21:40.195 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-03 13:21:40.327 - RealTimeSTT: root - INFO - voice activity detected
2024-10-03 13:21:40.327 - RealTimeSTT: root - INFO - recording started
2024-10-03 13:21:40.327 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'recording'
2024-10-03 13:21:40.337 - RealTimeSTT: root - INFO - State changed from 'recording' to 'inactive'
2024-10-03 13:21:40.337 - RealTimeSTT: root - DEBUG - Model tiny.en completed transcription in 0.20 seconds
2024-10-03 13:21:40.338 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a medical doctor providing consultations.'}, {'role': 'user', 'content': "\n        You are a medical doctor providing online consultations. Your task is to respond to users' health-related queries. \n        First, ask the user to provide essential details such as their name, age, specific symptoms, and duration of the issue. \n        Be mindful that the user's query may be converted from speech to text, so their input might have informal phrasing, errors, or lack punctuation. \n        After gathering these details, give a clear and thoughtful medical response based on the information provided.\n        \n\nUser Query: Yeah, I've been having severe headache from five days."}], 'model': 'gpt-3.5-turbo', 'max_tokens': 400, 'temperature': 0.7}}
2024-10-03 13:21:40.338 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-10-03 13:21:40.338 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-03 13:21:40.339 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-03 13:21:40.339 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-03 13:21:40.508 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000276601C72C0>
2024-10-03 13:21:40.508 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000276596C09D0> server_hostname='api.openai.com' timeout=5.0
2024-10-03 13:21:40.652 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000027657E960F0>
2024-10-03 13:21:40.653 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-03 13:21:40.653 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-03 13:21:40.653 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-03 13:21:40.653 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-03 13:21:40.653 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-03 13:21:40.943 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 401, b'Unauthorized', [(b'Date', b'Thu, 03 Oct 2024 13:21:40 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'301'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_9498b9bbeafd81be672942cc78b94a02'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ccd3c950d737853-CDG'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-03 13:21:40.943 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2024-10-03 13:21:40.943 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-03 13:21:40.944 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-03 13:21:40.944 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-03 13:21:40.944 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-03 13:21:40.944 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "401 Unauthorized" Headers({'date': 'Thu, 03 Oct 2024 13:21:40 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '301', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_9498b9bbeafd81be672942cc78b94a02', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ccd3c950d737853-CDG', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-03 13:21:40.944 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_9498b9bbeafd81be672942cc78b94a02
2024-10-03 13:21:40.944 - RealTimeSTT: openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\openai\_base_client.py", line 1030, in _request
    response.raise_for_status()
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\httpx\_models.py", line 763, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '401 Unauthorized' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/401
2024-10-03 13:21:40.946 - RealTimeSTT: openai._base_client - DEBUG - Not retrying
2024-10-03 13:21:40.946 - RealTimeSTT: openai._base_client - DEBUG - Re-raising status error
2024-10-04 09:59:06.903 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2024-10-04 09:59:06.907 - RealTimeSTT: root - INFO - Initializing audio recording (creating pyAudio input stream, sample rate: 16000 buffer size: 512
2024-10-04 09:59:06.908 - RealTimeSTT: root - INFO - Initializing WebRTC voice with Sensitivity 3
2024-10-04 09:59:06.908 - RealTimeSTT: root - DEBUG - WebRTC VAD voice activity detection engine initialized successfully
2024-10-04 09:59:07.250 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg6
2024-10-04 09:59:07.253 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg6 extension.
Traceback (most recent call last):
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torch\_ops.py", line 1295, in load_library
    ctypes.CDLL(path)
  File "C:\Python312\Lib\ctypes\__init__.py", line 379, in __init__
    self._handle = _dlopen(self._name, mode)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: Could not find module 'C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\lib\libtorio_ffmpeg6.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-04 09:59:07.256 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg5
2024-10-04 09:59:07.258 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg5 extension.
Traceback (most recent call last):
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torch\_ops.py", line 1295, in load_library
    ctypes.CDLL(path)
  File "C:\Python312\Lib\ctypes\__init__.py", line 379, in __init__
    self._handle = _dlopen(self._name, mode)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: Could not find module 'C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\lib\libtorio_ffmpeg5.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-04 09:59:07.258 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg4
2024-10-04 09:59:07.260 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg4 extension.
Traceback (most recent call last):
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torch\_ops.py", line 1295, in load_library
    ctypes.CDLL(path)
  File "C:\Python312\Lib\ctypes\__init__.py", line 379, in __init__
    self._handle = _dlopen(self._name, mode)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: Could not find module 'C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\lib\libtorio_ffmpeg4.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-04 09:59:07.260 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg
2024-10-04 09:59:07.261 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg extension.
Traceback (most recent call last):
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 106, in _find_versionsed_ffmpeg_extension
    raise RuntimeError(f"FFmpeg{version} extension is not available.")
RuntimeError: FFmpeg extension is not available.
2024-10-04 09:59:07.387 - RealTimeSTT: root - DEBUG - Silero VAD voice activity detection engine initialized successfully
2024-10-04 09:59:07.388 - RealTimeSTT: root - DEBUG - Starting realtime worker
2024-10-04 09:59:07.388 - RealTimeSTT: root - DEBUG - Waiting for main transcription model to start
2024-10-04 09:59:10.588 - RealTimeSTT: root - DEBUG - Main transcription model ready
2024-10-04 09:59:10.588 - RealTimeSTT: root - DEBUG - RealtimeSTT initialization completed successfully
2024-10-04 09:59:11.636 - RealTimeSTT: root - INFO - Setting listen time
2024-10-04 09:59:11.636 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-04 09:59:11.636 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-04 09:59:13.695 - RealTimeSTT: root - INFO - voice activity detected
2024-10-04 09:59:13.696 - RealTimeSTT: root - INFO - recording started
2024-10-04 09:59:13.696 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-04 09:59:13.696 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-04 09:59:18.368 - RealTimeSTT: root - INFO - recording stopped
2024-10-04 09:59:18.369 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-04 09:59:18.370 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-04 09:59:18.370 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-04 09:59:18.370 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-04 09:59:18.372 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-04 09:59:18.439 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-04 09:59:19.226 - RealTimeSTT: root - DEBUG - Model tiny.en completed transcription in 0.86 seconds
2024-10-04 09:59:19.229 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a medical doctor providing consultations.'}, {'role': 'user', 'content': "\n        You are a medical doctor providing online consultations. Your task is to respond to users' health-related queries. \n        First, ask the user to provide essential details such as their name, age, specific symptoms, and duration of the issue. \n        Be mindful that the user's query may be converted from speech to text, so their input might have informal phrasing, errors, or lack punctuation. \n        After gathering these details, give a clear and thoughtful medical response based on the information provided.\n        \n\nUser Query: Hello, my name is John and I am having severe headache from 5 days."}], 'model': 'gpt-3.5-turbo', 'max_tokens': 400, 'temperature': 0.7}}
2024-10-04 09:59:19.242 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-10-04 09:59:19.242 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-04 09:59:19.418 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F513E7B0B0>
2024-10-04 09:59:19.418 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F50CD58B50> server_hostname='api.openai.com' timeout=5.0
2024-10-04 09:59:19.572 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F513E7B680>
2024-10-04 09:59:19.572 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-04 09:59:19.573 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-04 09:59:19.573 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-04 09:59:19.573 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-04 09:59:19.573 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-04 09:59:19.848 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 401, b'Unauthorized', [(b'Date', b'Fri, 04 Oct 2024 04:59:19 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'301'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_6bb604c8cc8e87eafb2eb574ebbac8b4'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Mb3gnXEBtIVLPKv37WV1y7LGcCp45fK_NSUjs.OV1gY-1728017959-1.0.1.1-EAGU3fZN8x9lXqVC0hv9Tj0PU.lVlMSJPEgrOs6nKy1uiT5CQbK9LGuARiu7yMq4F04Tn7RecdW6ol9wZcq5Nw; path=/; expires=Fri, 04-Oct-24 05:29:19 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=i_LUuAc7buzw5FK0HXcMbVPoDrHTC8jRL_jHRgj8idM-1728017959762-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd29a17b8500076-CDG')])
2024-10-04 09:59:19.850 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2024-10-04 09:59:19.850 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-04 09:59:19.850 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-04 09:59:19.850 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-04 09:59:19.850 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-04 09:59:19.850 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "401 Unauthorized" Headers([('date', 'Fri, 04 Oct 2024 04:59:19 GMT'), ('content-type', 'application/json; charset=utf-8'), ('content-length', '301'), ('connection', 'keep-alive'), ('vary', 'Origin'), ('x-request-id', 'req_6bb604c8cc8e87eafb2eb574ebbac8b4'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=Mb3gnXEBtIVLPKv37WV1y7LGcCp45fK_NSUjs.OV1gY-1728017959-1.0.1.1-EAGU3fZN8x9lXqVC0hv9Tj0PU.lVlMSJPEgrOs6nKy1uiT5CQbK9LGuARiu7yMq4F04Tn7RecdW6ol9wZcq5Nw; path=/; expires=Fri, 04-Oct-24 05:29:19 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=i_LUuAc7buzw5FK0HXcMbVPoDrHTC8jRL_jHRgj8idM-1728017959762-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8cd29a17b8500076-CDG')])
2024-10-04 09:59:19.851 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_6bb604c8cc8e87eafb2eb574ebbac8b4
2024-10-04 09:59:19.851 - RealTimeSTT: openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\openai\_base_client.py", line 1030, in _request
    response.raise_for_status()
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\httpx\_models.py", line 763, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '401 Unauthorized' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/401
2024-10-04 09:59:19.866 - RealTimeSTT: openai._base_client - DEBUG - Not retrying
2024-10-04 09:59:19.866 - RealTimeSTT: openai._base_client - DEBUG - Re-raising status error
2024-10-04 09:59:26.180 - RealTimeSTT: root - INFO - voice activity detected
2024-10-04 09:59:26.181 - RealTimeSTT: root - INFO - recording started
2024-10-04 09:59:26.181 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'recording'
2024-10-04 10:10:41.057 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2024-10-04 10:10:41.058 - RealTimeSTT: root - INFO - Initializing audio recording (creating pyAudio input stream, sample rate: 16000 buffer size: 512
2024-10-04 10:10:41.059 - RealTimeSTT: root - INFO - Initializing WebRTC voice with Sensitivity 3
2024-10-04 10:10:41.059 - RealTimeSTT: root - DEBUG - WebRTC VAD voice activity detection engine initialized successfully
2024-10-04 10:10:41.671 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg6
2024-10-04 10:10:41.672 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg6 extension.
Traceback (most recent call last):
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torch\_ops.py", line 1295, in load_library
    ctypes.CDLL(path)
  File "C:\Python312\Lib\ctypes\__init__.py", line 379, in __init__
    self._handle = _dlopen(self._name, mode)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: Could not find module 'C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\lib\libtorio_ffmpeg6.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-04 10:10:41.672 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg5
2024-10-04 10:10:41.673 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg5 extension.
Traceback (most recent call last):
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torch\_ops.py", line 1295, in load_library
    ctypes.CDLL(path)
  File "C:\Python312\Lib\ctypes\__init__.py", line 379, in __init__
    self._handle = _dlopen(self._name, mode)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: Could not find module 'C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\lib\libtorio_ffmpeg5.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-04 10:10:41.673 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg4
2024-10-04 10:10:41.673 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg4 extension.
Traceback (most recent call last):
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torch\_ops.py", line 1295, in load_library
    ctypes.CDLL(path)
  File "C:\Python312\Lib\ctypes\__init__.py", line 379, in __init__
    self._handle = _dlopen(self._name, mode)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: Could not find module 'C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\lib\libtorio_ffmpeg4.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-04 10:10:41.674 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg
2024-10-04 10:10:41.674 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg extension.
Traceback (most recent call last):
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 106, in _find_versionsed_ffmpeg_extension
    raise RuntimeError(f"FFmpeg{version} extension is not available.")
RuntimeError: FFmpeg extension is not available.
2024-10-04 10:10:41.766 - RealTimeSTT: root - DEBUG - Silero VAD voice activity detection engine initialized successfully
2024-10-04 10:10:41.767 - RealTimeSTT: root - DEBUG - Starting realtime worker
2024-10-04 10:10:41.767 - RealTimeSTT: root - DEBUG - Waiting for main transcription model to start
2024-10-04 10:10:48.139 - RealTimeSTT: root - DEBUG - Main transcription model ready
2024-10-04 10:10:48.139 - RealTimeSTT: root - DEBUG - RealtimeSTT initialization completed successfully
2024-10-04 10:10:48.975 - RealTimeSTT: root - INFO - Setting listen time
2024-10-04 10:10:48.975 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-04 10:10:48.975 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-04 10:10:50.268 - RealTimeSTT: root - INFO - voice activity detected
2024-10-04 10:10:50.269 - RealTimeSTT: root - INFO - recording started
2024-10-04 10:10:50.269 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-04 10:10:50.269 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-04 10:10:56.669 - RealTimeSTT: root - INFO - recording stopped
2024-10-04 10:10:56.669 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-04 10:10:56.670 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-04 10:10:56.670 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-04 10:10:56.670 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-04 10:10:56.687 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-04 10:10:56.728 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-04 10:10:57.012 - RealTimeSTT: root - DEBUG - Model tiny.en completed transcription in 0.34 seconds
2024-10-04 10:10:57.014 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a medical doctor providing consultations.'}, {'role': 'user', 'content': "\n        You are a medical doctor providing online consultations. Your task is to respond to users' health-related queries. \n        First, ask the user to provide essential details such as their name, age, specific symptoms, and duration of the issue. \n        Be mindful that the user's query may be converted from speech to text, so their input might have informal phrasing, errors, or lack punctuation. \n        After gathering these details, give a clear and thoughtful medical response based on the information provided.\n        \n\nUser Query: Hello, my name is John and I'm having severe headache from five days."}], 'model': 'gpt-3.5-turbo', 'max_tokens': 400, 'temperature': 0.7}}
2024-10-04 10:10:57.028 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-10-04 10:10:57.028 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-04 10:10:57.173 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001E96715A990>
2024-10-04 10:10:57.173 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001E960128B50> server_hostname='api.openai.com' timeout=5.0
2024-10-04 10:10:57.324 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001E96040B6E0>
2024-10-04 10:10:57.324 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-04 10:10:57.324 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-04 10:10:57.324 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-04 10:10:57.325 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-04 10:10:57.325 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-04 10:10:58.707 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 05:10:58 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'nextweb-yrx64b'), (b'openai-processing-ms', b'810'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'4000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'3999431'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_d358c73457d8746e14c87d364e7722f8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=.F.0b9rDxeoDkNXWwSRUOe466MnPraKwX5N1QHsBGpY-1728018658-1.0.1.1-Tq8esJ9J4fDiPCmy3BXVn_j7v05pvYvuN_DVvofuBZoPFC6kZO1.AiF5NhrR2Cpq8gQ7Zq3xUoaV4npR03lbLg; path=/; expires=Fri, 04-Oct-24 05:40:58 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=7S46qbI61SFx374fWU9Wg8frjKt2o0hm7qtZOcuVLvo-1728018658615-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd2ab209b432a31-CDG'), (b'Content-Encoding', b'gzip')])
2024-10-04 10:10:58.708 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-04 10:10:58.708 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-04 10:10:58.709 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-04 10:10:58.709 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-04 10:10:58.709 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-04 10:10:58.710 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Fri, 04 Oct 2024 05:10:58 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'nextweb-yrx64b'), ('openai-processing-ms', '810'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('x-ratelimit-limit-requests', '5000'), ('x-ratelimit-limit-tokens', '4000000'), ('x-ratelimit-remaining-requests', '4999'), ('x-ratelimit-remaining-tokens', '3999431'), ('x-ratelimit-reset-requests', '12ms'), ('x-ratelimit-reset-tokens', '8ms'), ('x-request-id', 'req_d358c73457d8746e14c87d364e7722f8'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=.F.0b9rDxeoDkNXWwSRUOe466MnPraKwX5N1QHsBGpY-1728018658-1.0.1.1-Tq8esJ9J4fDiPCmy3BXVn_j7v05pvYvuN_DVvofuBZoPFC6kZO1.AiF5NhrR2Cpq8gQ7Zq3xUoaV4npR03lbLg; path=/; expires=Fri, 04-Oct-24 05:40:58 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=7S46qbI61SFx374fWU9Wg8frjKt2o0hm7qtZOcuVLvo-1728018658615-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8cd2ab209b432a31-CDG'), ('content-encoding', 'gzip')])
2024-10-04 10:10:58.710 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_d358c73457d8746e14c87d364e7722f8
2024-10-04 10:11:00.685 - RealTimeSTT: root - INFO - Setting listen time
2024-10-04 10:11:00.685 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-04 10:11:00.685 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-04 10:11:20.989 - RealTimeSTT: root - INFO - voice activity detected
2024-10-04 10:11:20.989 - RealTimeSTT: root - INFO - recording started
2024-10-04 10:11:20.989 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-04 10:11:20.989 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-04 10:11:23.293 - RealTimeSTT: root - INFO - recording stopped
2024-10-04 10:11:23.294 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-04 10:11:23.294 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-04 10:11:23.295 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-04 10:11:23.295 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-04 10:11:23.295 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-04 10:11:23.355 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-04 10:11:23.461 - RealTimeSTT: root - DEBUG - Model tiny.en completed transcription in 0.17 seconds
2024-10-04 10:11:23.462 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a medical doctor providing consultations.'}, {'role': 'user', 'content': "\n        You are a medical doctor providing online consultations. Your task is to respond to users' health-related queries. \n        First, ask the user to provide essential details such as their name, age, specific symptoms, and duration of the issue. \n        Be mindful that the user's query may be converted from speech to text, so their input might have informal phrasing, errors, or lack punctuation. \n        After gathering these details, give a clear and thoughtful medical response based on the information provided.\n        \n\nUser Query: Well it get critters."}], 'model': 'gpt-3.5-turbo', 'max_tokens': 400, 'temperature': 0.7}}
2024-10-04 10:11:23.462 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-10-04 10:11:23.462 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-04 10:11:23.462 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-04 10:11:23.462 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-04 10:11:23.607 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001E9670EE480>
2024-10-04 10:11:23.607 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001E960128B50> server_hostname='api.openai.com' timeout=5.0
2024-10-04 10:11:23.758 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001E9670ED7C0>
2024-10-04 10:11:23.759 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-04 10:11:23.759 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-04 10:11:23.759 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-04 10:11:23.759 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-04 10:11:23.759 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-04 10:11:24.997 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 05:11:24 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'nextweb-yrx64b'), (b'openai-processing-ms', b'781'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'4000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'3999443'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_c429f7e939bcc532a1550d93d453529a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd2abc5dce46eb5-CDG'), (b'Content-Encoding', b'gzip')])
2024-10-04 10:11:24.998 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-04 10:11:24.998 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-04 10:11:24.999 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-04 10:11:24.999 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-04 10:11:24.999 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-04 10:11:24.999 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 04 Oct 2024 05:11:24 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'nextweb-yrx64b', 'openai-processing-ms': '781', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '4000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '3999443', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_c429f7e939bcc532a1550d93d453529a', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd2abc5dce46eb5-CDG', 'content-encoding': 'gzip'})
2024-10-04 10:11:24.999 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_c429f7e939bcc532a1550d93d453529a
2024-10-04 10:11:27.306 - RealTimeSTT: root - INFO - Setting listen time
2024-10-04 10:11:27.306 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-04 10:11:27.306 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-04 10:11:34.381 - RealTimeSTT: root - INFO - KeyboardInterrupt in wait_audio, shutting down
2024-10-04 10:11:34.382 - RealTimeSTT: root - DEBUG - Finishing recording thread
2024-10-04 10:11:34.396 - RealTimeSTT: root - DEBUG - Terminating reader process
2024-10-04 10:11:34.684 - RealTimeSTT: root - DEBUG - Terminating transcription process
2024-10-04 10:11:34.727 - RealTimeSTT: root - DEBUG - Finishing realtime thread
2024-10-04 10:11:34.761 - RealTimeSTT: root - INFO - KeyboardInterrupt in text() method
2024-10-04 10:11:34.828 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-04 10:11:34.828 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-04 10:11:44.927 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2024-10-04 10:11:44.928 - RealTimeSTT: root - INFO - Initializing audio recording (creating pyAudio input stream, sample rate: 16000 buffer size: 512
2024-10-04 10:11:44.929 - RealTimeSTT: root - INFO - Initializing WebRTC voice with Sensitivity 3
2024-10-04 10:11:44.929 - RealTimeSTT: root - DEBUG - WebRTC VAD voice activity detection engine initialized successfully
2024-10-04 10:11:45.573 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg6
2024-10-04 10:11:45.573 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg6 extension.
Traceback (most recent call last):
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torch\_ops.py", line 1295, in load_library
    ctypes.CDLL(path)
  File "C:\Python312\Lib\ctypes\__init__.py", line 379, in __init__
    self._handle = _dlopen(self._name, mode)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: Could not find module 'C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\lib\libtorio_ffmpeg6.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-04 10:11:45.575 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg5
2024-10-04 10:11:45.576 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg5 extension.
Traceback (most recent call last):
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torch\_ops.py", line 1295, in load_library
    ctypes.CDLL(path)
  File "C:\Python312\Lib\ctypes\__init__.py", line 379, in __init__
    self._handle = _dlopen(self._name, mode)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: Could not find module 'C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\lib\libtorio_ffmpeg5.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-04 10:11:45.576 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg4
2024-10-04 10:11:45.577 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg4 extension.
Traceback (most recent call last):
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torch\_ops.py", line 1295, in load_library
    ctypes.CDLL(path)
  File "C:\Python312\Lib\ctypes\__init__.py", line 379, in __init__
    self._handle = _dlopen(self._name, mode)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: Could not find module 'C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\lib\libtorio_ffmpeg4.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-04 10:11:45.577 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg
2024-10-04 10:11:45.577 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg extension.
Traceback (most recent call last):
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 106, in _find_versionsed_ffmpeg_extension
    raise RuntimeError(f"FFmpeg{version} extension is not available.")
RuntimeError: FFmpeg extension is not available.
2024-10-04 10:11:45.686 - RealTimeSTT: root - DEBUG - Silero VAD voice activity detection engine initialized successfully
2024-10-04 10:11:45.687 - RealTimeSTT: root - DEBUG - Starting realtime worker
2024-10-04 10:11:45.687 - RealTimeSTT: root - DEBUG - Waiting for main transcription model to start
2024-10-04 10:11:47.744 - RealTimeSTT: root - DEBUG - Main transcription model ready
2024-10-04 10:11:47.745 - RealTimeSTT: root - DEBUG - RealtimeSTT initialization completed successfully
2024-10-04 10:11:48.531 - RealTimeSTT: root - INFO - Setting listen time
2024-10-04 10:11:48.531 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-04 10:11:48.531 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-04 10:11:50.417 - RealTimeSTT: root - INFO - voice activity detected
2024-10-04 10:11:50.418 - RealTimeSTT: root - INFO - recording started
2024-10-04 10:11:50.418 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-04 10:11:50.422 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-04 10:11:54.837 - RealTimeSTT: root - INFO - recording stopped
2024-10-04 10:11:54.837 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-04 10:11:54.839 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-04 10:11:54.839 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-04 10:11:54.839 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-04 10:11:54.847 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-04 10:11:54.897 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-04 10:11:55.077 - RealTimeSTT: root - DEBUG - Model tiny.en completed transcription in 0.24 seconds
2024-10-04 10:11:55.079 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a medical doctor providing consultations.'}, {'role': 'user', 'content': "\n        You are a medical doctor providing online consultations. Your task is to respond to users' health-related queries. \n        First, ask the user to provide essential details such as their name, age, specific symptoms, and duration of the issue. \n        Be mindful that the user's query may be converted from speech to text, so their input might have informal phrasing, errors, or lack punctuation. \n        After gathering these details, give a clear and thoughtful medical response based on the information provided.\n        \n\nUser Query: Hello, I want to make some appointments related to my dog health."}], 'model': 'gpt-3.5-turbo', 'max_tokens': 400, 'temperature': 0.7}}
2024-10-04 10:11:55.095 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-10-04 10:11:55.095 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-04 10:11:55.266 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000024042251DC0>
2024-10-04 10:11:55.266 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002403B508B50> server_hostname='api.openai.com' timeout=5.0
2024-10-04 10:11:55.411 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000240432DB050>
2024-10-04 10:11:55.411 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-04 10:11:55.411 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-04 10:11:55.411 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-04 10:11:55.411 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-04 10:11:55.411 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-04 10:11:56.551 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 05:11:56 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'nextweb-yrx64b'), (b'openai-processing-ms', b'690'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'4000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'3999431'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_f761ef708f0856cd090e1b864bd8538e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=gRvkLMb24tmxRh4qgTVNwR6HhgZ5AmZmXe4ZqfsEbtk-1728018716-1.0.1.1-E.UhDuOo8woM8iRrlbSDpXC0FXaZ6N3vSVTlfQpbGEH_2fSts52pB_l.EVr8TQqm4S6sogFG2rEbrvcXrWLVVA; path=/; expires=Fri, 04-Oct-24 05:41:56 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=B6JufnMsgrIWzBsiZAPazhTQ8LXLz96dl9IeXk4td3o-1728018716465-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd2ac8bae4d017d-CDG'), (b'Content-Encoding', b'gzip')])
2024-10-04 10:11:56.552 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-04 10:11:56.552 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-04 10:11:56.554 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-04 10:11:56.554 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-04 10:11:56.554 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-04 10:11:56.554 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Fri, 04 Oct 2024 05:11:56 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'nextweb-yrx64b'), ('openai-processing-ms', '690'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('x-ratelimit-limit-requests', '5000'), ('x-ratelimit-limit-tokens', '4000000'), ('x-ratelimit-remaining-requests', '4999'), ('x-ratelimit-remaining-tokens', '3999431'), ('x-ratelimit-reset-requests', '12ms'), ('x-ratelimit-reset-tokens', '8ms'), ('x-request-id', 'req_f761ef708f0856cd090e1b864bd8538e'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=gRvkLMb24tmxRh4qgTVNwR6HhgZ5AmZmXe4ZqfsEbtk-1728018716-1.0.1.1-E.UhDuOo8woM8iRrlbSDpXC0FXaZ6N3vSVTlfQpbGEH_2fSts52pB_l.EVr8TQqm4S6sogFG2rEbrvcXrWLVVA; path=/; expires=Fri, 04-Oct-24 05:41:56 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=B6JufnMsgrIWzBsiZAPazhTQ8LXLz96dl9IeXk4td3o-1728018716465-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8cd2ac8bae4d017d-CDG'), ('content-encoding', 'gzip')])
2024-10-04 10:11:56.555 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_f761ef708f0856cd090e1b864bd8538e
2024-10-04 10:11:58.039 - RealTimeSTT: root - INFO - Setting listen time
2024-10-04 10:11:58.039 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-04 10:11:58.040 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-04 10:12:06.925 - RealTimeSTT: root - INFO - voice activity detected
2024-10-04 10:12:06.926 - RealTimeSTT: root - INFO - recording started
2024-10-04 10:12:06.926 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-04 10:12:06.926 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-04 10:12:08.531 - RealTimeSTT: root - INFO - recording stopped
2024-10-04 10:12:08.532 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-04 10:12:08.532 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-04 10:12:08.532 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-04 10:12:08.533 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-04 10:12:08.533 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-04 10:12:08.592 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-04 10:12:08.708 - RealTimeSTT: root - DEBUG - Model tiny.en completed transcription in 0.18 seconds
2024-10-04 10:12:08.709 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a medical doctor providing consultations.'}, {'role': 'user', 'content': "\n        You are a medical doctor providing online consultations. Your task is to respond to users' health-related queries. \n        First, ask the user to provide essential details such as their name, age, specific symptoms, and duration of the issue. \n        Be mindful that the user's query may be converted from speech to text, so their input might have informal phrasing, errors, or lack punctuation. \n        After gathering these details, give a clear and thoughtful medical response based on the information provided.\n        \n\nUser Query: "}], 'model': 'gpt-3.5-turbo', 'max_tokens': 400, 'temperature': 0.7}}
2024-10-04 10:12:08.709 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-10-04 10:12:08.709 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-04 10:12:08.709 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-04 10:12:08.709 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-04 10:12:08.851 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000240433ED7C0>
2024-10-04 10:12:08.851 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002403B508B50> server_hostname='api.openai.com' timeout=5.0
2024-10-04 10:12:09.000 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000240434BA2D0>
2024-10-04 10:12:09.000 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-04 10:12:09.001 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-04 10:12:09.001 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-04 10:12:09.001 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-04 10:12:09.001 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-04 10:12:09.735 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 05:12:09 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'nextweb-yrx64b'), (b'openai-processing-ms', b'283'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'4000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'3999447'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_2869b5d2928e73034c0cff664de3bd5c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd2ace09d87bb33-CDG'), (b'Content-Encoding', b'gzip')])
2024-10-04 10:12:09.735 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-04 10:12:09.736 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-04 10:12:09.736 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-04 10:12:09.736 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-04 10:12:09.737 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-04 10:12:09.737 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 04 Oct 2024 05:12:09 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'nextweb-yrx64b', 'openai-processing-ms': '283', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '4000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '3999447', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_2869b5d2928e73034c0cff664de3bd5c', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd2ace09d87bb33-CDG', 'content-encoding': 'gzip'})
2024-10-04 10:12:09.737 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_2869b5d2928e73034c0cff664de3bd5c
2024-10-04 10:12:11.627 - RealTimeSTT: root - INFO - Setting listen time
2024-10-04 10:12:11.627 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-04 10:12:11.627 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-04 10:12:11.792 - RealTimeSTT: root - INFO - voice activity detected
2024-10-04 10:12:11.792 - RealTimeSTT: root - INFO - recording started
2024-10-04 10:12:11.793 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-04 10:12:11.793 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-04 10:12:13.590 - RealTimeSTT: root - INFO - recording stopped
2024-10-04 10:12:13.590 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-04 10:12:13.590 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-04 10:12:13.590 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-04 10:12:13.590 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-04 10:12:13.611 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-04 10:12:13.650 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-04 10:12:13.672 - RealTimeSTT: root - DEBUG - Model tiny.en completed transcription in 0.08 seconds
2024-10-04 10:12:13.673 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a medical doctor providing consultations.'}, {'role': 'user', 'content': "\n        You are a medical doctor providing online consultations. Your task is to respond to users' health-related queries. \n        First, ask the user to provide essential details such as their name, age, specific symptoms, and duration of the issue. \n        Be mindful that the user's query may be converted from speech to text, so their input might have informal phrasing, errors, or lack punctuation. \n        After gathering these details, give a clear and thoughtful medical response based on the information provided.\n        \n\nUser Query: Okay, okay."}], 'model': 'gpt-3.5-turbo', 'max_tokens': 400, 'temperature': 0.7}}
2024-10-04 10:12:13.673 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-10-04 10:12:13.673 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-04 10:12:13.674 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-04 10:12:13.674 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-04 10:12:13.674 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-04 10:12:13.674 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-04 10:12:14.505 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 05:12:14 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'nextweb-yrx64b'), (b'openai-processing-ms', b'388'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'4000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'3999445'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_a1abc262adeb24cab8a521b18b18e600'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd2acfdca55bb33-CDG'), (b'Content-Encoding', b'gzip')])
2024-10-04 10:12:14.505 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-04 10:12:14.506 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-04 10:12:14.506 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-04 10:12:14.506 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-04 10:12:14.506 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-04 10:12:14.506 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 04 Oct 2024 05:12:14 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'nextweb-yrx64b', 'openai-processing-ms': '388', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '4000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '3999445', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_a1abc262adeb24cab8a521b18b18e600', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd2acfdca55bb33-CDG', 'content-encoding': 'gzip'})
2024-10-04 10:12:14.506 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_a1abc262adeb24cab8a521b18b18e600
2024-10-04 10:12:15.340 - RealTimeSTT: root - INFO - Setting listen time
2024-10-04 10:12:15.340 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-04 10:12:15.340 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-04 10:12:16.079 - RealTimeSTT: root - INFO - voice activity detected
2024-10-04 10:12:16.079 - RealTimeSTT: root - INFO - recording started
2024-10-04 10:12:16.079 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-04 10:12:16.079 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-04 10:12:22.224 - RealTimeSTT: root - INFO - recording stopped
2024-10-04 10:12:22.225 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-04 10:12:22.225 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-04 10:12:22.225 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-04 10:12:22.225 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-04 10:12:22.225 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-04 10:12:22.285 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-04 10:12:22.481 - RealTimeSTT: root - DEBUG - Model tiny.en completed transcription in 0.26 seconds
2024-10-04 10:12:22.482 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a medical doctor providing consultations.'}, {'role': 'user', 'content': "\n        You are a medical doctor providing online consultations. Your task is to respond to users' health-related queries. \n        First, ask the user to provide essential details such as their name, age, specific symptoms, and duration of the issue. \n        Be mindful that the user's query may be converted from speech to text, so their input might have informal phrasing, errors, or lack punctuation. \n        After gathering these details, give a clear and thoughtful medical response based on the information provided.\n        \n\nUser Query: Okay, my name is Billah Wies and I don't have given name to my dog."}], 'model': 'gpt-3.5-turbo', 'max_tokens': 400, 'temperature': 0.7}}
2024-10-04 10:12:22.482 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-10-04 10:12:22.482 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-04 10:12:22.482 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-04 10:12:22.483 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-04 10:12:22.641 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000240433259D0>
2024-10-04 10:12:22.641 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002403B508B50> server_hostname='api.openai.com' timeout=5.0
2024-10-04 10:12:22.789 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000024043256420>
2024-10-04 10:12:22.790 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-04 10:12:22.790 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-04 10:12:22.790 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-04 10:12:22.790 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-04 10:12:22.790 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-04 10:12:24.016 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 05:12:23 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'nextweb-yrx64b'), (b'openai-processing-ms', b'770'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'4000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'3999431'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_81fcec25f382358afd0a6d9a93a934db'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd2ad36cf289f09-CDG'), (b'Content-Encoding', b'gzip')])
2024-10-04 10:12:24.016 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-04 10:12:24.017 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-04 10:12:24.017 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-04 10:12:24.017 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-04 10:12:24.017 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-04 10:12:24.017 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 04 Oct 2024 05:12:23 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'nextweb-yrx64b', 'openai-processing-ms': '770', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '4000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '3999431', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_81fcec25f382358afd0a6d9a93a934db', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd2ad36cf289f09-CDG', 'content-encoding': 'gzip'})
2024-10-04 10:12:24.017 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_81fcec25f382358afd0a6d9a93a934db
2024-10-04 10:12:24.769 - RealTimeSTT: root - INFO - Setting listen time
2024-10-04 10:12:24.769 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-04 10:12:24.769 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-04 10:12:29.904 - RealTimeSTT: root - INFO - voice activity detected
2024-10-04 10:12:29.904 - RealTimeSTT: root - INFO - recording started
2024-10-04 10:12:29.904 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-04 10:12:29.904 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-04 10:12:34.129 - RealTimeSTT: root - INFO - KeyboardInterrupt in wait_audio, shutting down
2024-10-04 10:12:34.129 - RealTimeSTT: root - DEBUG - Finishing recording thread
2024-10-04 10:12:34.130 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-04 10:12:34.130 - RealTimeSTT: root - DEBUG - Terminating reader process
2024-10-04 10:12:34.404 - RealTimeSTT: root - DEBUG - Terminating transcription process
2024-10-04 10:12:34.528 - RealTimeSTT: root - DEBUG - Finishing realtime thread
2024-10-04 10:12:34.567 - RealTimeSTT: root - INFO - KeyboardInterrupt in text() method
2024-10-04 10:12:34.655 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-04 10:12:34.655 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-04 10:24:06.397 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2024-10-04 10:24:06.398 - RealTimeSTT: root - INFO - Initializing audio recording (creating pyAudio input stream, sample rate: 16000 buffer size: 512
2024-10-04 10:24:06.399 - RealTimeSTT: root - INFO - Initializing WebRTC voice with Sensitivity 3
2024-10-04 10:24:06.399 - RealTimeSTT: root - DEBUG - WebRTC VAD voice activity detection engine initialized successfully
2024-10-04 10:24:07.012 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg6
2024-10-04 10:24:07.013 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg6 extension.
Traceback (most recent call last):
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torch\_ops.py", line 1295, in load_library
    ctypes.CDLL(path)
  File "C:\Python312\Lib\ctypes\__init__.py", line 379, in __init__
    self._handle = _dlopen(self._name, mode)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: Could not find module 'C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\lib\libtorio_ffmpeg6.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-04 10:24:07.013 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg5
2024-10-04 10:24:07.014 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg5 extension.
Traceback (most recent call last):
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torch\_ops.py", line 1295, in load_library
    ctypes.CDLL(path)
  File "C:\Python312\Lib\ctypes\__init__.py", line 379, in __init__
    self._handle = _dlopen(self._name, mode)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: Could not find module 'C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\lib\libtorio_ffmpeg5.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-04 10:24:07.014 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg4
2024-10-04 10:24:07.014 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg4 extension.
Traceback (most recent call last):
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torch\_ops.py", line 1295, in load_library
    ctypes.CDLL(path)
  File "C:\Python312\Lib\ctypes\__init__.py", line 379, in __init__
    self._handle = _dlopen(self._name, mode)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: Could not find module 'C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\lib\libtorio_ffmpeg4.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-04 10:24:07.015 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg
2024-10-04 10:24:07.015 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg extension.
Traceback (most recent call last):
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 106, in _find_versionsed_ffmpeg_extension
    raise RuntimeError(f"FFmpeg{version} extension is not available.")
RuntimeError: FFmpeg extension is not available.
2024-10-04 10:24:07.105 - RealTimeSTT: root - DEBUG - Silero VAD voice activity detection engine initialized successfully
2024-10-04 10:24:07.106 - RealTimeSTT: root - DEBUG - Starting realtime worker
2024-10-04 10:24:07.106 - RealTimeSTT: root - DEBUG - Waiting for main transcription model to start
2024-10-04 10:24:09.633 - RealTimeSTT: root - DEBUG - Main transcription model ready
2024-10-04 10:24:09.633 - RealTimeSTT: root - DEBUG - RealtimeSTT initialization completed successfully
2024-10-04 10:24:10.418 - RealTimeSTT: root - INFO - Setting listen time
2024-10-04 10:24:10.418 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-04 10:24:10.418 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-04 10:24:12.187 - RealTimeSTT: root - INFO - voice activity detected
2024-10-04 10:24:12.187 - RealTimeSTT: root - INFO - recording started
2024-10-04 10:24:12.187 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-04 10:24:12.188 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-04 10:24:17.114 - RealTimeSTT: root - INFO - recording stopped
2024-10-04 10:24:17.115 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-04 10:24:17.116 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-04 10:24:17.116 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-04 10:24:17.116 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-04 10:24:17.134 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-04 10:24:17.175 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-04 10:24:17.371 - RealTimeSTT: root - DEBUG - Model tiny.en completed transcription in 0.25 seconds
2024-10-04 10:24:43.547 - RealTimeSTT: root - INFO - voice activity detected
2024-10-04 10:24:43.548 - RealTimeSTT: root - INFO - recording started
2024-10-04 10:24:43.548 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'recording'
2024-10-04 10:25:31.242 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2024-10-04 10:25:31.243 - RealTimeSTT: root - INFO - Initializing audio recording (creating pyAudio input stream, sample rate: 16000 buffer size: 512
2024-10-04 10:25:31.244 - RealTimeSTT: root - INFO - Initializing WebRTC voice with Sensitivity 3
2024-10-04 10:25:31.244 - RealTimeSTT: root - DEBUG - WebRTC VAD voice activity detection engine initialized successfully
2024-10-04 10:25:31.862 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg6
2024-10-04 10:25:31.862 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg6 extension.
Traceback (most recent call last):
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torch\_ops.py", line 1295, in load_library
    ctypes.CDLL(path)
  File "C:\Python312\Lib\ctypes\__init__.py", line 379, in __init__
    self._handle = _dlopen(self._name, mode)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: Could not find module 'C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\lib\libtorio_ffmpeg6.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-04 10:25:31.863 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg5
2024-10-04 10:25:31.864 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg5 extension.
Traceback (most recent call last):
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torch\_ops.py", line 1295, in load_library
    ctypes.CDLL(path)
  File "C:\Python312\Lib\ctypes\__init__.py", line 379, in __init__
    self._handle = _dlopen(self._name, mode)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: Could not find module 'C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\lib\libtorio_ffmpeg5.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-04 10:25:31.864 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg4
2024-10-04 10:25:31.864 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg4 extension.
Traceback (most recent call last):
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torch\_ops.py", line 1295, in load_library
    ctypes.CDLL(path)
  File "C:\Python312\Lib\ctypes\__init__.py", line 379, in __init__
    self._handle = _dlopen(self._name, mode)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: Could not find module 'C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\lib\libtorio_ffmpeg4.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-04 10:25:31.864 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg
2024-10-04 10:25:31.864 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg extension.
Traceback (most recent call last):
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 106, in _find_versionsed_ffmpeg_extension
    raise RuntimeError(f"FFmpeg{version} extension is not available.")
RuntimeError: FFmpeg extension is not available.
2024-10-04 10:25:31.948 - RealTimeSTT: root - DEBUG - Silero VAD voice activity detection engine initialized successfully
2024-10-04 10:25:31.949 - RealTimeSTT: root - DEBUG - Starting realtime worker
2024-10-04 10:25:31.949 - RealTimeSTT: root - DEBUG - Waiting for main transcription model to start
2024-10-04 10:25:33.634 - RealTimeSTT: root - DEBUG - Main transcription model ready
2024-10-04 10:25:33.635 - RealTimeSTT: root - DEBUG - RealtimeSTT initialization completed successfully
2024-10-04 10:25:34.547 - RealTimeSTT: root - INFO - Setting listen time
2024-10-04 10:25:34.547 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-04 10:25:34.547 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-04 10:25:36.091 - RealTimeSTT: root - INFO - voice activity detected
2024-10-04 10:25:36.092 - RealTimeSTT: root - INFO - recording started
2024-10-04 10:25:36.092 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-04 10:25:36.092 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-04 10:25:40.317 - RealTimeSTT: root - INFO - recording stopped
2024-10-04 10:25:40.318 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-04 10:25:40.319 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-04 10:25:40.319 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-04 10:25:40.319 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-04 10:25:40.321 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-04 10:25:40.378 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-04 10:25:40.500 - RealTimeSTT: root - DEBUG - Model tiny.en completed transcription in 0.18 seconds
2024-10-04 10:25:40.502 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a medical doctor providing consultations.'}, {'role': 'system', 'content': "\n        You are a medical doctor providing online consultations. Your task is to respond to users' health-related queries. \n        First, ask the user to provide essential details such as their name, age, specific symptoms, and duration of the issue. \n        Be mindful that the user's query may be converted from speech to text, so their input might have informal phrasing, errors, or lack punctuation. \n        After gathering these details, give a clear and thoughtful medical response based on the information provided.\n        "}, {'role': 'user', 'content': 'User Query: Hello, my name is John and I am having severe headache from 5 days.'}], 'model': 'gpt-3.5-turbo', 'max_tokens': 400, 'temperature': 0.7}}
2024-10-04 10:25:40.515 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-10-04 10:25:40.516 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-04 10:25:40.684 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C65A609D90>
2024-10-04 10:25:40.684 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001C6536C8C50> server_hostname='api.openai.com' timeout=5.0
2024-10-04 10:25:40.829 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C65A6CEF30>
2024-10-04 10:25:40.829 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-04 10:25:40.830 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-04 10:25:40.830 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-04 10:25:40.830 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-04 10:25:40.830 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-04 10:25:42.965 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 05:25:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'nextweb-yrx64b'), (b'openai-processing-ms', b'1701'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'4000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'3999431'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_a3c8ec8c6f29e671ebd1b10fc3af2ec1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Et90UtLgveC8vCm7naWcnZhcrWnHhbngnQYOG4QPuB4-1728019542-1.0.1.1-cSLi48RnG96FWZSB0Tgk3OLWV_qWZ3f9VJZYtOBzmz3mghuZQShfFUkSkqREOYX1ItBwNxq.vJ.TO7gbkKJlgA; path=/; expires=Fri, 04-Oct-24 05:55:42 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=7ypsSqxFJVPW29D.6ytdD3gkWszRlVJMFQ6rv4_U684-1728019542874-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd2c0b27b1cf184-CDG'), (b'Content-Encoding', b'gzip')])
2024-10-04 10:25:42.966 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-04 10:25:42.966 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-04 10:25:42.967 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-04 10:25:42.967 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-04 10:25:42.967 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-04 10:25:42.967 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Fri, 04 Oct 2024 05:25:42 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'nextweb-yrx64b'), ('openai-processing-ms', '1701'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('x-ratelimit-limit-requests', '5000'), ('x-ratelimit-limit-tokens', '4000000'), ('x-ratelimit-remaining-requests', '4999'), ('x-ratelimit-remaining-tokens', '3999431'), ('x-ratelimit-reset-requests', '12ms'), ('x-ratelimit-reset-tokens', '8ms'), ('x-request-id', 'req_a3c8ec8c6f29e671ebd1b10fc3af2ec1'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=Et90UtLgveC8vCm7naWcnZhcrWnHhbngnQYOG4QPuB4-1728019542-1.0.1.1-cSLi48RnG96FWZSB0Tgk3OLWV_qWZ3f9VJZYtOBzmz3mghuZQShfFUkSkqREOYX1ItBwNxq.vJ.TO7gbkKJlgA; path=/; expires=Fri, 04-Oct-24 05:55:42 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=7ypsSqxFJVPW29D.6ytdD3gkWszRlVJMFQ6rv4_U684-1728019542874-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8cd2c0b27b1cf184-CDG'), ('content-encoding', 'gzip')])
2024-10-04 10:25:42.967 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_a3c8ec8c6f29e671ebd1b10fc3af2ec1
2024-10-04 10:25:44.504 - RealTimeSTT: root - INFO - Setting listen time
2024-10-04 10:25:44.504 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-04 10:25:44.504 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-04 10:26:02.589 - RealTimeSTT: root - INFO - KeyboardInterrupt in wait_audio, shutting down
2024-10-04 10:26:02.590 - RealTimeSTT: root - DEBUG - Finishing recording thread
2024-10-04 10:26:02.604 - RealTimeSTT: root - DEBUG - Terminating reader process
2024-10-04 10:26:02.903 - RealTimeSTT: root - INFO - KeyboardInterrupt in text() method
2024-10-04 10:26:56.753 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2024-10-04 10:26:56.755 - RealTimeSTT: root - INFO - Initializing audio recording (creating pyAudio input stream, sample rate: 16000 buffer size: 512
2024-10-04 10:26:56.755 - RealTimeSTT: root - INFO - Initializing WebRTC voice with Sensitivity 3
2024-10-04 10:26:56.755 - RealTimeSTT: root - DEBUG - WebRTC VAD voice activity detection engine initialized successfully
2024-10-04 10:26:57.385 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg6
2024-10-04 10:26:57.386 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg6 extension.
Traceback (most recent call last):
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torch\_ops.py", line 1295, in load_library
    ctypes.CDLL(path)
  File "C:\Python312\Lib\ctypes\__init__.py", line 379, in __init__
    self._handle = _dlopen(self._name, mode)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: Could not find module 'C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\lib\libtorio_ffmpeg6.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-04 10:26:57.387 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg5
2024-10-04 10:26:57.387 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg5 extension.
Traceback (most recent call last):
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torch\_ops.py", line 1295, in load_library
    ctypes.CDLL(path)
  File "C:\Python312\Lib\ctypes\__init__.py", line 379, in __init__
    self._handle = _dlopen(self._name, mode)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: Could not find module 'C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\lib\libtorio_ffmpeg5.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-04 10:26:57.387 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg4
2024-10-04 10:26:57.388 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg4 extension.
Traceback (most recent call last):
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torch\_ops.py", line 1295, in load_library
    ctypes.CDLL(path)
  File "C:\Python312\Lib\ctypes\__init__.py", line 379, in __init__
    self._handle = _dlopen(self._name, mode)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: Could not find module 'C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\lib\libtorio_ffmpeg4.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-04 10:26:57.388 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg
2024-10-04 10:26:57.388 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg extension.
Traceback (most recent call last):
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 106, in _find_versionsed_ffmpeg_extension
    raise RuntimeError(f"FFmpeg{version} extension is not available.")
RuntimeError: FFmpeg extension is not available.
2024-10-04 10:26:57.477 - RealTimeSTT: root - DEBUG - Silero VAD voice activity detection engine initialized successfully
2024-10-04 10:26:57.478 - RealTimeSTT: root - DEBUG - Starting realtime worker
2024-10-04 10:26:57.478 - RealTimeSTT: root - DEBUG - Waiting for main transcription model to start
2024-10-04 10:26:59.124 - RealTimeSTT: root - DEBUG - Main transcription model ready
2024-10-04 10:26:59.124 - RealTimeSTT: root - DEBUG - RealtimeSTT initialization completed successfully
2024-10-04 10:27:00.065 - RealTimeSTT: root - INFO - Setting listen time
2024-10-04 10:27:00.065 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-04 10:27:00.065 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-04 10:27:01.853 - RealTimeSTT: root - INFO - voice activity detected
2024-10-04 10:27:01.853 - RealTimeSTT: root - INFO - recording started
2024-10-04 10:27:01.854 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-04 10:27:01.854 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-04 10:27:06.141 - RealTimeSTT: root - INFO - recording stopped
2024-10-04 10:27:06.141 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-04 10:27:06.143 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-04 10:27:06.143 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-04 10:27:06.143 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-04 10:27:06.157 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-04 10:27:06.200 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-04 10:27:06.355 - RealTimeSTT: root - DEBUG - Model tiny.en completed transcription in 0.21 seconds
2024-10-04 10:27:06.357 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a medical doctor providing consultations.'}, {'role': 'system', 'content': "\n        You are a medical doctor providing online consultations. Your task is to respond to users' health-related queries. \n        First, ask the user to provide essential details such as their name, age, specific symptoms, and duration of the issue. \n        Be mindful that the user's query may be converted from speech to text, so their input might have informal phrasing, errors, or lack punctuation. \n        After gathering these details, give a clear and thoughtful medical response based on the information provided.\n        "}, {'role': 'user', 'content': 'User Query: Hello, my name is John and I am having severe headaches from five days.'}], 'model': 'gpt-3.5-turbo', 'max_tokens': 400, 'temperature': 0.7}}
2024-10-04 10:27:06.368 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-10-04 10:27:06.369 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-04 10:27:06.431 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000016F9A24D070>
2024-10-04 10:27:06.431 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000016F932A8C50> server_hostname='api.openai.com' timeout=5.0
2024-10-04 10:27:06.453 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000016F9A2FB1D0>
2024-10-04 10:27:06.453 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-04 10:27:06.454 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-04 10:27:06.454 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-04 10:27:06.454 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-04 10:27:06.454 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-04 10:27:08.641 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 05:27:08 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'nextweb-yrx64b'), (b'openai-processing-ms', b'1536'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'4000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'3999429'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_fe28e102a430107d26dc7b3cbac9c45b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=TjKIcPEOcH76.3Dh_cqX02r7jeFSquv4VxdJryhbALA-1728019628-1.0.1.1-OozbFRbSp3qB1aMmJQ4GxlzxgDFaDHxcuQqb.bo8ywAdSO9cxsc31.1AZ5E4xA5MGTTnvtwPfmx5QIipF9.vCQ; path=/; expires=Fri, 04-Oct-24 05:57:08 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=seBucsjTKftuxQqaEhY808ZY3Ni_JUCmBCtmf6EXse4-1728019628614-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd2c2c94992c605-KHI'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-04 10:27:08.643 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-04 10:27:08.644 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-04 10:27:08.644 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-04 10:27:08.645 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-04 10:27:08.645 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-04 10:27:08.645 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Fri, 04 Oct 2024 05:27:08 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'nextweb-yrx64b'), ('openai-processing-ms', '1536'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('x-ratelimit-limit-requests', '5000'), ('x-ratelimit-limit-tokens', '4000000'), ('x-ratelimit-remaining-requests', '4999'), ('x-ratelimit-remaining-tokens', '3999429'), ('x-ratelimit-reset-requests', '12ms'), ('x-ratelimit-reset-tokens', '8ms'), ('x-request-id', 'req_fe28e102a430107d26dc7b3cbac9c45b'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=TjKIcPEOcH76.3Dh_cqX02r7jeFSquv4VxdJryhbALA-1728019628-1.0.1.1-OozbFRbSp3qB1aMmJQ4GxlzxgDFaDHxcuQqb.bo8ywAdSO9cxsc31.1AZ5E4xA5MGTTnvtwPfmx5QIipF9.vCQ; path=/; expires=Fri, 04-Oct-24 05:57:08 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=seBucsjTKftuxQqaEhY808ZY3Ni_JUCmBCtmf6EXse4-1728019628614-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8cd2c2c94992c605-KHI'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2024-10-04 10:27:08.645 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_fe28e102a430107d26dc7b3cbac9c45b
2024-10-04 10:27:10.199 - RealTimeSTT: root - INFO - Setting listen time
2024-10-04 10:27:10.199 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-04 10:27:10.199 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-04 10:27:44.256 - RealTimeSTT: root - INFO - KeyboardInterrupt in wait_audio, shutting down
2024-10-04 10:27:44.257 - RealTimeSTT: root - DEBUG - Finishing recording thread
2024-10-04 10:27:44.272 - RealTimeSTT: root - DEBUG - Terminating reader process
2024-10-04 10:27:44.518 - RealTimeSTT: root - INFO - KeyboardInterrupt in text() method
2024-10-04 10:27:44.730 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-04 10:27:44.730 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-04 10:27:47.912 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2024-10-04 10:27:47.913 - RealTimeSTT: root - INFO - Initializing audio recording (creating pyAudio input stream, sample rate: 16000 buffer size: 512
2024-10-04 10:27:47.914 - RealTimeSTT: root - INFO - Initializing WebRTC voice with Sensitivity 3
2024-10-04 10:27:47.914 - RealTimeSTT: root - DEBUG - WebRTC VAD voice activity detection engine initialized successfully
2024-10-04 10:27:48.544 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg6
2024-10-04 10:27:48.544 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg6 extension.
Traceback (most recent call last):
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torch\_ops.py", line 1295, in load_library
    ctypes.CDLL(path)
  File "C:\Python312\Lib\ctypes\__init__.py", line 379, in __init__
    self._handle = _dlopen(self._name, mode)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: Could not find module 'C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\lib\libtorio_ffmpeg6.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-04 10:27:48.545 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg5
2024-10-04 10:27:48.545 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg5 extension.
Traceback (most recent call last):
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torch\_ops.py", line 1295, in load_library
    ctypes.CDLL(path)
  File "C:\Python312\Lib\ctypes\__init__.py", line 379, in __init__
    self._handle = _dlopen(self._name, mode)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: Could not find module 'C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\lib\libtorio_ffmpeg5.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-04 10:27:48.546 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg4
2024-10-04 10:27:48.546 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg4 extension.
Traceback (most recent call last):
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torch\_ops.py", line 1295, in load_library
    ctypes.CDLL(path)
  File "C:\Python312\Lib\ctypes\__init__.py", line 379, in __init__
    self._handle = _dlopen(self._name, mode)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: Could not find module 'C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\lib\libtorio_ffmpeg4.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-04 10:27:48.546 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg
2024-10-04 10:27:48.546 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg extension.
Traceback (most recent call last):
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 106, in _find_versionsed_ffmpeg_extension
    raise RuntimeError(f"FFmpeg{version} extension is not available.")
RuntimeError: FFmpeg extension is not available.
2024-10-04 10:27:48.642 - RealTimeSTT: root - DEBUG - Silero VAD voice activity detection engine initialized successfully
2024-10-04 10:27:48.644 - RealTimeSTT: root - DEBUG - Starting realtime worker
2024-10-04 10:27:48.644 - RealTimeSTT: root - DEBUG - Waiting for main transcription model to start
2024-10-04 10:27:50.132 - RealTimeSTT: root - DEBUG - Main transcription model ready
2024-10-04 10:27:50.133 - RealTimeSTT: root - DEBUG - RealtimeSTT initialization completed successfully
2024-10-04 10:27:51.000 - RealTimeSTT: root - INFO - Setting listen time
2024-10-04 10:27:51.000 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-04 10:27:51.000 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-04 10:27:52.605 - RealTimeSTT: root - INFO - voice activity detected
2024-10-04 10:27:52.605 - RealTimeSTT: root - INFO - recording started
2024-10-04 10:27:52.605 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-04 10:27:52.606 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-04 10:27:59.899 - RealTimeSTT: root - INFO - recording stopped
2024-10-04 10:27:59.900 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-04 10:27:59.901 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-04 10:27:59.902 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-04 10:27:59.902 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-04 10:27:59.922 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-04 10:27:59.960 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-04 10:28:00.360 - RealTimeSTT: root - DEBUG - Model tiny.en completed transcription in 0.46 seconds
2024-10-04 10:28:00.362 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a medical doctor providing consultations.'}, {'role': 'system', 'content': "\n        You are a medical doctor providing online consultations. Your task is to respond to users' health-related queries. \n        First, ask the user to provide essential details such as their name, age, specific symptoms, and duration of the issue. \n        Be mindful that the user's query may be converted from speech to text, so their input might have informal phrasing, errors, or lack punctuation. \n        After gathering these details, give a clear and thoughtful medical response based on the information provided.\n        Keep your responses very short.\n        "}, {'role': 'user', 'content': 'User Query: Hello, I am not feeling well from 5 days. I have a severe headache when I use laptop or phone. My name is John.'}], 'model': 'gpt-3.5-turbo', 'max_tokens': 400, 'temperature': 0.7}}
2024-10-04 10:28:00.377 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-10-04 10:28:00.377 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-04 10:28:00.630 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001FFFF62B1D0>
2024-10-04 10:28:00.630 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001FFFE6E8D50> server_hostname='api.openai.com' timeout=5.0
2024-10-04 10:28:00.653 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001FFFF1FC3B0>
2024-10-04 10:28:00.653 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-04 10:28:00.654 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-04 10:28:00.654 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-04 10:28:00.654 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-04 10:28:00.654 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-04 10:28:02.326 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 05:28:02 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'nextweb-yrx64b'), (b'openai-processing-ms', b'551'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'4000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'3999409'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_d5362a45f32741f19d09170a524fe2eb'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=wgDSJ4_APnWE6vFMoPXuktrJ7VrUofhxT.4NTMXep64-1728019682-1.0.1.1-zYrE2MsUCSEt5.eGEIGmQ13Oy2DTBi.t.VbwOrs08IQRkMu2DB2jUV9OHLHs9Fbmlw8pFMQbdjphTuOmZkTvsw; path=/; expires=Fri, 04-Oct-24 05:58:02 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=SPEJr5E_UMIEPjK3U.d7Vx.VBh7mjQUUmEkjfdHly.I-1728019682295-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd2c41c0b3cc60d-KHI'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-04 10:28:02.327 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-04 10:28:02.327 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-04 10:28:02.328 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-04 10:28:02.329 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-04 10:28:02.329 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-04 10:28:02.329 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Fri, 04 Oct 2024 05:28:02 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'nextweb-yrx64b'), ('openai-processing-ms', '551'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('x-ratelimit-limit-requests', '5000'), ('x-ratelimit-limit-tokens', '4000000'), ('x-ratelimit-remaining-requests', '4999'), ('x-ratelimit-remaining-tokens', '3999409'), ('x-ratelimit-reset-requests', '12ms'), ('x-ratelimit-reset-tokens', '8ms'), ('x-request-id', 'req_d5362a45f32741f19d09170a524fe2eb'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=wgDSJ4_APnWE6vFMoPXuktrJ7VrUofhxT.4NTMXep64-1728019682-1.0.1.1-zYrE2MsUCSEt5.eGEIGmQ13Oy2DTBi.t.VbwOrs08IQRkMu2DB2jUV9OHLHs9Fbmlw8pFMQbdjphTuOmZkTvsw; path=/; expires=Fri, 04-Oct-24 05:58:02 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=SPEJr5E_UMIEPjK3U.d7Vx.VBh7mjQUUmEkjfdHly.I-1728019682295-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8cd2c41c0b3cc60d-KHI'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2024-10-04 10:28:02.329 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_d5362a45f32741f19d09170a524fe2eb
2024-10-04 10:28:03.812 - RealTimeSTT: root - INFO - Setting listen time
2024-10-04 10:28:03.813 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-04 10:28:03.813 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-04 10:28:06.045 - RealTimeSTT: root - INFO - voice activity detected
2024-10-04 10:28:06.046 - RealTimeSTT: root - INFO - recording started
2024-10-04 10:28:06.046 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-04 10:28:06.050 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-04 10:28:10.454 - RealTimeSTT: root - INFO - recording stopped
2024-10-04 10:28:10.455 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-04 10:28:10.456 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-04 10:28:10.456 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-04 10:28:10.457 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-04 10:28:10.458 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-04 10:28:10.525 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-04 10:28:10.745 - RealTimeSTT: root - DEBUG - Model tiny.en completed transcription in 0.29 seconds
2024-10-04 10:28:10.747 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a medical doctor providing consultations.'}, {'role': 'system', 'content': "\n        You are a medical doctor providing online consultations. Your task is to respond to users' health-related queries. \n        First, ask the user to provide essential details such as their name, age, specific symptoms, and duration of the issue. \n        Be mindful that the user's query may be converted from speech to text, so their input might have informal phrasing, errors, or lack punctuation. \n        After gathering these details, give a clear and thoughtful medical response based on the information provided.\n        Keep your responses very short.\n        "}, {'role': 'assistant', 'content': 'Hello John. It sounds like you may be experiencing digital eye strain from prolonged use of screens. Try taking breaks, using artificial tears, and adjusting the screen brightness. If the headache persists, consider seeing a doctor for further evaluation.'}, {'role': 'user', 'content': 'User Query: But soon, all of you have been experiencing difficult history for the whole process for me.'}], 'model': 'gpt-3.5-turbo', 'max_tokens': 400, 'temperature': 0.7}}
2024-10-04 10:28:10.747 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-10-04 10:28:10.747 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-04 10:28:10.747 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-04 10:28:10.747 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-04 10:28:10.855 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001FFFF5BAF30>
2024-10-04 10:28:10.855 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001FFFE6E8D50> server_hostname='api.openai.com' timeout=5.0
2024-10-04 10:28:10.959 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001FFFF5BB4D0>
2024-10-04 10:28:10.959 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-04 10:28:10.959 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-04 10:28:10.959 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-04 10:28:10.959 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-04 10:28:10.959 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-04 10:28:11.723 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 05:28:11 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'nextweb-yrx64b'), (b'openai-processing-ms', b'270'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'4000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'3999350'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'9ms'), (b'x-request-id', b'req_0978b1c97f08d019ef15f35db35624fa'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd2c45caaf2ce2b-SIN'), (b'Content-Encoding', b'gzip')])
2024-10-04 10:28:11.724 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-04 10:28:11.725 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-04 10:28:11.725 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-04 10:28:11.725 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-04 10:28:11.725 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-04 10:28:11.725 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 04 Oct 2024 05:28:11 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'nextweb-yrx64b', 'openai-processing-ms': '270', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '4000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '3999350', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '9ms', 'x-request-id': 'req_0978b1c97f08d019ef15f35db35624fa', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd2c45caaf2ce2b-SIN', 'content-encoding': 'gzip'})
2024-10-04 10:28:11.726 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_0978b1c97f08d019ef15f35db35624fa
2024-10-04 10:28:13.461 - RealTimeSTT: root - INFO - Setting listen time
2024-10-04 10:28:13.461 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-04 10:28:13.461 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-04 10:28:15.706 - RealTimeSTT: root - INFO - voice activity detected
2024-10-04 10:28:15.706 - RealTimeSTT: root - INFO - recording started
2024-10-04 10:28:15.706 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-04 10:28:15.707 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-04 10:28:21.974 - RealTimeSTT: root - INFO - recording stopped
2024-10-04 10:28:21.974 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-04 10:28:21.975 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-04 10:28:21.975 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-04 10:28:21.975 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-04 10:28:21.991 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-04 10:28:22.045 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-04 10:28:22.245 - RealTimeSTT: root - DEBUG - Model tiny.en completed transcription in 0.27 seconds
2024-10-04 10:28:22.247 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a medical doctor providing consultations.'}, {'role': 'system', 'content': "\n        You are a medical doctor providing online consultations. Your task is to respond to users' health-related queries. \n        First, ask the user to provide essential details such as their name, age, specific symptoms, and duration of the issue. \n        Be mindful that the user's query may be converted from speech to text, so their input might have informal phrasing, errors, or lack punctuation. \n        After gathering these details, give a clear and thoughtful medical response based on the information provided.\n        Keep your responses very short.\n        "}, {'role': 'assistant', 'content': 'Hello John. It sounds like you may be experiencing digital eye strain from prolonged use of screens. Try taking breaks, using artificial tears, and adjusting the screen brightness. If the headache persists, consider seeing a doctor for further evaluation.'}, {'role': 'assistant', 'content': "I'm sorry, could you please provide more specific details about your symptoms or health concern?"}, {'role': 'user', 'content': 'User Query: Like what?'}], 'model': 'gpt-3.5-turbo', 'max_tokens': 400, 'temperature': 0.7}}
2024-10-04 10:28:22.248 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-10-04 10:28:22.248 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-04 10:28:22.248 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-04 10:28:22.248 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-04 10:28:22.263 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001FFFF637A40>
2024-10-04 10:28:22.263 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001FFFE6E8D50> server_hostname='api.openai.com' timeout=5.0
2024-10-04 10:28:22.283 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001FFFD3068D0>
2024-10-04 10:28:22.283 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-04 10:28:22.283 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-04 10:28:22.283 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-04 10:28:22.283 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-04 10:28:22.283 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-04 10:28:22.990 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 05:28:22 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'nextweb-yrx64b'), (b'openai-processing-ms', b'399'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'4000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'3999345'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'9ms'), (b'x-request-id', b'req_a3627712a27b0793596ce05807134272'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd2c4a33db6c615-KHI'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-04 10:28:22.991 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-04 10:28:22.991 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-04 10:28:22.993 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-04 10:28:22.993 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-04 10:28:22.993 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-04 10:28:22.994 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 04 Oct 2024 05:28:22 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'nextweb-yrx64b', 'openai-processing-ms': '399', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '4000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '3999345', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '9ms', 'x-request-id': 'req_a3627712a27b0793596ce05807134272', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd2c4a33db6c615-KHI', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-04 10:28:22.994 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_a3627712a27b0793596ce05807134272
2024-10-04 10:28:24.720 - RealTimeSTT: root - INFO - Setting listen time
2024-10-04 10:28:24.720 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-04 10:28:24.720 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-04 10:28:33.118 - RealTimeSTT: root - INFO - voice activity detected
2024-10-04 10:28:33.118 - RealTimeSTT: root - INFO - recording started
2024-10-04 10:28:33.119 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-04 10:28:33.119 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-04 10:28:40.666 - RealTimeSTT: root - INFO - recording stopped
2024-10-04 10:28:40.666 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-04 10:28:40.667 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-04 10:28:40.667 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-04 10:28:40.668 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-04 10:28:40.682 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-04 10:28:40.726 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-04 10:28:40.919 - RealTimeSTT: root - INFO - voice activity detected
2024-10-04 10:28:40.919 - RealTimeSTT: root - INFO - recording started
2024-10-04 10:28:40.919 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'recording'
2024-10-04 10:28:40.989 - RealTimeSTT: root - INFO - State changed from 'recording' to 'inactive'
2024-10-04 10:28:40.989 - RealTimeSTT: root - DEBUG - Model tiny.en completed transcription in 0.32 seconds
2024-10-04 10:28:40.991 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a medical doctor providing consultations.'}, {'role': 'system', 'content': "\n        You are a medical doctor providing online consultations. Your task is to respond to users' health-related queries. \n        First, ask the user to provide essential details such as their name, age, specific symptoms, and duration of the issue. \n        Be mindful that the user's query may be converted from speech to text, so their input might have informal phrasing, errors, or lack punctuation. \n        After gathering these details, give a clear and thoughtful medical response based on the information provided.\n        Keep your responses very short.\n        "}, {'role': 'assistant', 'content': 'Hello John. It sounds like you may be experiencing digital eye strain from prolonged use of screens. Try taking breaks, using artificial tears, and adjusting the screen brightness. If the headache persists, consider seeing a doctor for further evaluation.'}, {'role': 'assistant', 'content': "I'm sorry, could you please provide more specific details about your symptoms or health concern?"}, {'role': 'assistant', 'content': 'Please provide details such as your name, age, specific symptoms, and how long you have been experiencing them.'}, {'role': 'user', 'content': 'User Query: My name is John, I am 25 years old and I am having severe headache in my left side of the head.'}], 'model': 'gpt-3.5-turbo', 'max_tokens': 400, 'temperature': 0.7}}
2024-10-04 10:28:40.991 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-10-04 10:28:40.992 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-04 10:28:40.992 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-04 10:28:40.992 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-04 10:28:41.022 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001FFFF5A2330>
2024-10-04 10:28:41.022 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001FFFE6E8D50> server_hostname='api.openai.com' timeout=5.0
2024-10-04 10:28:41.040 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001FFFF5A2570>
2024-10-04 10:28:41.040 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-04 10:28:41.040 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-04 10:28:41.040 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-04 10:28:41.040 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-04 10:28:41.040 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-04 10:28:42.268 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 05:28:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'nextweb-yrx64b'), (b'openai-processing-ms', b'776'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'4000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'3999295'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'10ms'), (b'x-request-id', b'req_2d61dbd5a1343900c9833fe7b7087306'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd2c5186bbfc60d-KHI'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-04 10:28:42.269 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-04 10:28:42.269 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-04 10:28:42.269 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-04 10:28:42.270 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-04 10:28:42.270 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-04 10:28:42.270 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 04 Oct 2024 05:28:42 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'nextweb-yrx64b', 'openai-processing-ms': '776', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '4000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '3999295', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '10ms', 'x-request-id': 'req_2d61dbd5a1343900c9833fe7b7087306', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd2c5186bbfc60d-KHI', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-04 10:28:42.270 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_2d61dbd5a1343900c9833fe7b7087306
2024-10-04 10:28:42.814 - RealTimeSTT: root - INFO - Setting listen time
2024-10-04 10:28:42.815 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-04 10:28:44.191 - RealTimeSTT: root - INFO - recording stopped
2024-10-04 10:28:44.191 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-04 10:28:44.192 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-04 10:28:44.192 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-04 10:28:44.192 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-04 10:28:44.194 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-04 10:28:44.252 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-04 10:28:44.268 - RealTimeSTT: root - DEBUG - Model tiny.en completed transcription in 0.08 seconds
2024-10-04 10:28:44.270 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a medical doctor providing consultations.'}, {'role': 'system', 'content': "\n        You are a medical doctor providing online consultations. Your task is to respond to users' health-related queries. \n        First, ask the user to provide essential details such as their name, age, specific symptoms, and duration of the issue. \n        Be mindful that the user's query may be converted from speech to text, so their input might have informal phrasing, errors, or lack punctuation. \n        After gathering these details, give a clear and thoughtful medical response based on the information provided.\n        Keep your responses very short.\n        "}, {'role': 'assistant', 'content': 'Hello John. It sounds like you may be experiencing digital eye strain from prolonged use of screens. Try taking breaks, using artificial tears, and adjusting the screen brightness. If the headache persists, consider seeing a doctor for further evaluation.'}, {'role': 'assistant', 'content': "I'm sorry, could you please provide more specific details about your symptoms or health concern?"}, {'role': 'assistant', 'content': 'Please provide details such as your name, age, specific symptoms, and how long you have been experiencing them.'}, {'role': 'assistant', 'content': 'Hello John. A severe headache on one side of the head could be due to various reasons such as tension headaches, migraines, or cluster headaches. It would be best to consult with a healthcare provider to determine the exact cause and receive appropriate treatment. In the meantime, you can try resting in a quiet, dark room and using over-the-counter pain relievers if needed.'}, {'role': 'user', 'content': 'User Query: And I am having it from five days.'}], 'model': 'gpt-3.5-turbo', 'max_tokens': 400, 'temperature': 0.7}}
2024-10-04 10:28:44.271 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-10-04 10:28:44.271 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-04 10:28:44.271 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-04 10:28:44.271 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-04 10:28:44.271 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-04 10:28:44.271 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-04 10:28:45.345 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 05:28:45 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'nextweb-yrx64b'), (b'openai-processing-ms', b'622'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'4000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'3999215'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'11ms'), (b'x-request-id', b'req_a82d725bbabe2094d624dd31854f5648'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd2c52c9cb5c60d-KHI'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-04 10:28:45.346 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-04 10:28:45.346 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-04 10:28:45.347 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-04 10:28:45.347 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-04 10:28:45.347 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-04 10:28:45.347 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 04 Oct 2024 05:28:45 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'nextweb-yrx64b', 'openai-processing-ms': '622', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '4000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '3999215', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '11ms', 'x-request-id': 'req_a82d725bbabe2094d624dd31854f5648', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd2c52c9cb5c60d-KHI', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-04 10:28:45.348 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_a82d725bbabe2094d624dd31854f5648
2024-10-04 10:28:45.904 - RealTimeSTT: root - INFO - Setting listen time
2024-10-04 10:28:45.905 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-04 10:28:45.905 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-04 10:28:50.652 - RealTimeSTT: root - INFO - voice activity detected
2024-10-04 10:28:50.652 - RealTimeSTT: root - INFO - recording started
2024-10-04 10:28:50.652 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-04 10:28:50.653 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-04 10:28:51.800 - RealTimeSTT: root - INFO - recording stopped
2024-10-04 10:28:51.800 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-04 10:28:51.801 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-04 10:28:51.801 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-04 10:28:51.801 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-04 10:28:51.810 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-04 10:28:51.871 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-04 10:28:51.975 - RealTimeSTT: root - DEBUG - Model tiny.en completed transcription in 0.17 seconds
2024-10-04 10:28:51.978 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a medical doctor providing consultations.'}, {'role': 'system', 'content': "\n        You are a medical doctor providing online consultations. Your task is to respond to users' health-related queries. \n        First, ask the user to provide essential details such as their name, age, specific symptoms, and duration of the issue. \n        Be mindful that the user's query may be converted from speech to text, so their input might have informal phrasing, errors, or lack punctuation. \n        After gathering these details, give a clear and thoughtful medical response based on the information provided.\n        Keep your responses very short.\n        "}, {'role': 'assistant', 'content': 'Hello John. It sounds like you may be experiencing digital eye strain from prolonged use of screens. Try taking breaks, using artificial tears, and adjusting the screen brightness. If the headache persists, consider seeing a doctor for further evaluation.'}, {'role': 'assistant', 'content': "I'm sorry, could you please provide more specific details about your symptoms or health concern?"}, {'role': 'assistant', 'content': 'Please provide details such as your name, age, specific symptoms, and how long you have been experiencing them.'}, {'role': 'assistant', 'content': 'Hello John. A severe headache on one side of the head could be due to various reasons such as tension headaches, migraines, or cluster headaches. It would be best to consult with a healthcare provider to determine the exact cause and receive appropriate treatment. In the meantime, you can try resting in a quiet, dark room and using over-the-counter pain relievers if needed.'}, {'role': 'assistant', 'content': "Thank you for sharing that information, John. Since you've been experiencing this severe headache for five days, it's important to seek medical advice promptly. Persistent headaches may require further evaluation to rule out any underlying issues. I recommend scheduling an appointment with a healthcare provider for a thorough assessment and appropriate management."}, {'role': 'user', 'content': 'User Query: '}], 'model': 'gpt-3.5-turbo', 'max_tokens': 400, 'temperature': 0.7}}
2024-10-04 10:28:51.978 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-10-04 10:28:51.979 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-04 10:28:51.979 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-04 10:28:51.979 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-04 10:28:51.992 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001FFFD3068D0>
2024-10-04 10:28:51.992 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001FFFE6E8D50> server_hostname='api.openai.com' timeout=5.0
2024-10-04 10:28:52.011 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001FFFF64F290>
2024-10-04 10:28:52.011 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-04 10:28:52.011 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-04 10:28:52.011 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-04 10:28:52.011 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-04 10:28:52.011 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-04 10:28:52.797 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 05:28:52 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'nextweb-yrx64b'), (b'openai-processing-ms', b'344'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'4000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'3999131'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'13ms'), (b'x-request-id', b'req_004ad3ec2ba85b6d5052af7c877e671c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd2c55cfea0c601-KHI'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-04 10:28:52.798 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-04 10:28:52.798 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-04 10:28:52.799 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-04 10:28:52.799 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-04 10:28:52.801 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-04 10:28:52.801 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 04 Oct 2024 05:28:52 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'nextweb-yrx64b', 'openai-processing-ms': '344', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '4000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '3999131', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '13ms', 'x-request-id': 'req_004ad3ec2ba85b6d5052af7c877e671c', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd2c55cfea0c601-KHI', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-04 10:28:52.801 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_004ad3ec2ba85b6d5052af7c877e671c
2024-10-04 10:28:54.202 - RealTimeSTT: root - INFO - Setting listen time
2024-10-04 10:28:54.202 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-04 10:28:54.202 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-04 10:28:58.840 - RealTimeSTT: root - INFO - voice activity detected
2024-10-04 10:28:58.841 - RealTimeSTT: root - INFO - recording started
2024-10-04 10:28:58.841 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-04 10:28:58.841 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-04 10:29:01.846 - RealTimeSTT: root - INFO - recording stopped
2024-10-04 10:29:01.846 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-04 10:29:01.847 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-04 10:29:01.847 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-04 10:29:01.847 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-04 10:29:01.847 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-04 10:29:01.917 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-04 10:29:02.044 - RealTimeSTT: root - DEBUG - Model tiny.en completed transcription in 0.20 seconds
2024-10-04 10:29:02.047 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a medical doctor providing consultations.'}, {'role': 'system', 'content': "\n        You are a medical doctor providing online consultations. Your task is to respond to users' health-related queries. \n        First, ask the user to provide essential details such as their name, age, specific symptoms, and duration of the issue. \n        Be mindful that the user's query may be converted from speech to text, so their input might have informal phrasing, errors, or lack punctuation. \n        After gathering these details, give a clear and thoughtful medical response based on the information provided.\n        Keep your responses very short.\n        "}, {'role': 'assistant', 'content': 'Hello John. It sounds like you may be experiencing digital eye strain from prolonged use of screens. Try taking breaks, using artificial tears, and adjusting the screen brightness. If the headache persists, consider seeing a doctor for further evaluation.'}, {'role': 'assistant', 'content': "I'm sorry, could you please provide more specific details about your symptoms or health concern?"}, {'role': 'assistant', 'content': 'Please provide details such as your name, age, specific symptoms, and how long you have been experiencing them.'}, {'role': 'assistant', 'content': 'Hello John. A severe headache on one side of the head could be due to various reasons such as tension headaches, migraines, or cluster headaches. It would be best to consult with a healthcare provider to determine the exact cause and receive appropriate treatment. In the meantime, you can try resting in a quiet, dark room and using over-the-counter pain relievers if needed.'}, {'role': 'assistant', 'content': "Thank you for sharing that information, John. Since you've been experiencing this severe headache for five days, it's important to seek medical advice promptly. Persistent headaches may require further evaluation to rule out any underlying issues. I recommend scheduling an appointment with a healthcare provider for a thorough assessment and appropriate management."}, {'role': 'assistant', 'content': "I'm here to help. Please go ahead and provide me with details about your health concern or any symptoms you are experiencing."}, {'role': 'user', 'content': 'User Query: '}], 'model': 'gpt-3.5-turbo', 'max_tokens': 400, 'temperature': 0.7}}
2024-10-04 10:29:02.047 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-10-04 10:29:02.047 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-04 10:29:02.047 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-04 10:29:02.047 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-04 10:29:02.228 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001FFFF70C230>
2024-10-04 10:29:02.228 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001FFFE6E8D50> server_hostname='api.openai.com' timeout=5.0
2024-10-04 10:29:02.294 - RealTimeSTT: root - INFO - voice activity detected
2024-10-04 10:29:02.294 - RealTimeSTT: root - INFO - recording started
2024-10-04 10:29:02.295 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'recording'
2024-10-04 10:29:02.381 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001FFFF64F650>
2024-10-04 10:29:02.381 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-04 10:29:02.381 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-04 10:29:02.381 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-04 10:29:02.381 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-04 10:29:02.381 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-04 10:29:03.207 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 05:29:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'nextweb-yrx64b'), (b'openai-processing-ms', b'373'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'4000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'3999098'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'13ms'), (b'x-request-id', b'req_d439320d394541e91f3cad633470cad7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd2c59e2f276f10-CDG'), (b'Content-Encoding', b'gzip')])
2024-10-04 10:29:03.207 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-04 10:29:03.207 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-04 10:29:03.207 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-04 10:29:03.207 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-04 10:29:03.207 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-04 10:29:03.207 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 04 Oct 2024 05:29:03 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'nextweb-yrx64b', 'openai-processing-ms': '373', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '4000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '3999098', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '13ms', 'x-request-id': 'req_d439320d394541e91f3cad633470cad7', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd2c59e2f276f10-CDG', 'content-encoding': 'gzip'})
2024-10-04 10:29:03.208 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_d439320d394541e91f3cad633470cad7
2024-10-04 10:29:04.033 - RealTimeSTT: root - INFO - Setting listen time
2024-10-04 10:29:04.033 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-04 10:29:04.732 - RealTimeSTT: root - INFO - recording stopped
2024-10-04 10:29:04.732 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-04 10:29:04.732 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-04 10:29:04.732 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-04 10:29:04.732 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-04 10:29:04.743 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-04 10:29:04.793 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-04 10:29:04.935 - RealTimeSTT: root - DEBUG - Model tiny.en completed transcription in 0.20 seconds
2024-10-04 10:29:04.938 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a medical doctor providing consultations.'}, {'role': 'system', 'content': "\n        You are a medical doctor providing online consultations. Your task is to respond to users' health-related queries. \n        First, ask the user to provide essential details such as their name, age, specific symptoms, and duration of the issue. \n        Be mindful that the user's query may be converted from speech to text, so their input might have informal phrasing, errors, or lack punctuation. \n        After gathering these details, give a clear and thoughtful medical response based on the information provided.\n        Keep your responses very short.\n        "}, {'role': 'assistant', 'content': 'Hello John. It sounds like you may be experiencing digital eye strain from prolonged use of screens. Try taking breaks, using artificial tears, and adjusting the screen brightness. If the headache persists, consider seeing a doctor for further evaluation.'}, {'role': 'assistant', 'content': "I'm sorry, could you please provide more specific details about your symptoms or health concern?"}, {'role': 'assistant', 'content': 'Please provide details such as your name, age, specific symptoms, and how long you have been experiencing them.'}, {'role': 'assistant', 'content': 'Hello John. A severe headache on one side of the head could be due to various reasons such as tension headaches, migraines, or cluster headaches. It would be best to consult with a healthcare provider to determine the exact cause and receive appropriate treatment. In the meantime, you can try resting in a quiet, dark room and using over-the-counter pain relievers if needed.'}, {'role': 'assistant', 'content': "Thank you for sharing that information, John. Since you've been experiencing this severe headache for five days, it's important to seek medical advice promptly. Persistent headaches may require further evaluation to rule out any underlying issues. I recommend scheduling an appointment with a healthcare provider for a thorough assessment and appropriate management."}, {'role': 'assistant', 'content': "I'm here to help. Please go ahead and provide me with details about your health concern or any symptoms you are experiencing."}, {'role': 'assistant', 'content': "I'm here to help. Please go ahead and provide me with details about your health concern or any symptoms you are experiencing."}, {'role': 'user', 'content': 'User Query: This little time is good.'}], 'model': 'gpt-3.5-turbo', 'max_tokens': 400, 'temperature': 0.7}}
2024-10-04 10:29:04.938 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-10-04 10:29:04.938 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-04 10:29:04.938 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-04 10:29:04.938 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-04 10:29:04.938 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-04 10:29:04.938 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-04 10:29:05.629 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 05:29:05 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'nextweb-yrx64b'), (b'openai-processing-ms', b'243'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'4000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'3999061'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'14ms'), (b'x-request-id', b'req_913d6ab579d6e4700b66ee3cd1e7ded2'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd2c5ae2e576f10-CDG'), (b'Content-Encoding', b'gzip')])
2024-10-04 10:29:05.629 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-04 10:29:05.629 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-04 10:29:05.630 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-04 10:29:05.630 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-04 10:29:05.630 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-04 10:29:05.630 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 04 Oct 2024 05:29:05 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'nextweb-yrx64b', 'openai-processing-ms': '243', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '4000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '3999061', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '14ms', 'x-request-id': 'req_913d6ab579d6e4700b66ee3cd1e7ded2', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd2c5ae2e576f10-CDG', 'content-encoding': 'gzip'})
2024-10-04 10:29:05.630 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_913d6ab579d6e4700b66ee3cd1e7ded2
2024-10-04 10:29:06.176 - RealTimeSTT: root - INFO - Setting listen time
2024-10-04 10:29:06.176 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-04 10:29:06.176 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-04 10:29:07.158 - RealTimeSTT: root - INFO - KeyboardInterrupt in wait_audio, shutting down
2024-10-04 10:29:07.158 - RealTimeSTT: root - DEBUG - Finishing recording thread
2024-10-04 10:29:07.160 - RealTimeSTT: root - DEBUG - Terminating reader process
2024-10-04 10:29:07.398 - RealTimeSTT: root - DEBUG - Terminating transcription process
2024-10-04 10:29:15.651 - RealTimeSTT: root - INFO - KeyboardInterrupt in text() method
2024-10-04 10:29:15.728 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-04 10:29:15.728 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-04 10:29:42.774 - RealTimeSTT: root - INFO - Starting RealTimeSTT
2024-10-04 10:29:42.775 - RealTimeSTT: root - INFO - Initializing audio recording (creating pyAudio input stream, sample rate: 16000 buffer size: 512
2024-10-04 10:29:42.776 - RealTimeSTT: root - INFO - Initializing WebRTC voice with Sensitivity 3
2024-10-04 10:29:42.776 - RealTimeSTT: root - DEBUG - WebRTC VAD voice activity detection engine initialized successfully
2024-10-04 10:29:43.393 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg6
2024-10-04 10:29:43.394 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg6 extension.
Traceback (most recent call last):
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torch\_ops.py", line 1295, in load_library
    ctypes.CDLL(path)
  File "C:\Python312\Lib\ctypes\__init__.py", line 379, in __init__
    self._handle = _dlopen(self._name, mode)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: Could not find module 'C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\lib\libtorio_ffmpeg6.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-04 10:29:43.394 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg5
2024-10-04 10:29:43.395 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg5 extension.
Traceback (most recent call last):
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torch\_ops.py", line 1295, in load_library
    ctypes.CDLL(path)
  File "C:\Python312\Lib\ctypes\__init__.py", line 379, in __init__
    self._handle = _dlopen(self._name, mode)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: Could not find module 'C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\lib\libtorio_ffmpeg5.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-04 10:29:43.395 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg4
2024-10-04 10:29:43.395 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg4 extension.
Traceback (most recent call last):
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 108, in _find_versionsed_ffmpeg_extension
    _load_lib(lib)
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 94, in _load_lib
    torch.ops.load_library(path)
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torch\_ops.py", line 1295, in load_library
    ctypes.CDLL(path)
  File "C:\Python312\Lib\ctypes\__init__.py", line 379, in __init__
    self._handle = _dlopen(self._name, mode)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: Could not find module 'C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\lib\libtorio_ffmpeg4.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
2024-10-04 10:29:43.396 - RealTimeSTT: torio._extension.utils - DEBUG - Loading FFmpeg
2024-10-04 10:29:43.396 - RealTimeSTT: torio._extension.utils - DEBUG - Failed to load FFmpeg extension.
Traceback (most recent call last):
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 116, in _find_ffmpeg_extension
    ext = _find_versionsed_ffmpeg_extension(ffmpeg_ver)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RBTG V2\Desktop\AI VERTICALSOLS\STT\env\Lib\site-packages\torio\_extension\utils.py", line 106, in _find_versionsed_ffmpeg_extension
    raise RuntimeError(f"FFmpeg{version} extension is not available.")
RuntimeError: FFmpeg extension is not available.
2024-10-04 10:29:43.485 - RealTimeSTT: root - DEBUG - Silero VAD voice activity detection engine initialized successfully
2024-10-04 10:29:43.486 - RealTimeSTT: root - DEBUG - Starting realtime worker
2024-10-04 10:29:43.486 - RealTimeSTT: root - DEBUG - Waiting for main transcription model to start
2024-10-04 10:29:45.177 - RealTimeSTT: root - DEBUG - Main transcription model ready
2024-10-04 10:29:45.178 - RealTimeSTT: root - DEBUG - RealtimeSTT initialization completed successfully
2024-10-04 10:29:46.146 - RealTimeSTT: root - INFO - Setting listen time
2024-10-04 10:29:46.146 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-04 10:29:46.146 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-04 10:29:47.874 - RealTimeSTT: root - INFO - voice activity detected
2024-10-04 10:29:47.874 - RealTimeSTT: root - INFO - recording started
2024-10-04 10:29:47.874 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-04 10:29:47.874 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-04 10:29:52.039 - RealTimeSTT: root - INFO - recording stopped
2024-10-04 10:29:52.039 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-04 10:29:52.041 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-04 10:29:52.041 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-04 10:29:52.041 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-04 10:29:52.061 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-04 10:29:52.100 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-04 10:29:52.331 - RealTimeSTT: root - DEBUG - Model tiny.en completed transcription in 0.29 seconds
2024-10-04 10:29:52.333 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a medical doctor providing consultations.'}, {'role': 'system', 'content': "\n        You are a medical doctor providing online consultations. Your task is to respond to users' health-related queries. \n        First, ask the user to provide essential details such as their name, age, specific symptoms, and duration of the issue. \n        Be mindful that the user's query may be converted from speech to text, so their input might have informal phrasing, errors, or lack punctuation. \n        After gathering these details, give a clear and thoughtful medical response based on the information provided.\n        Keep your responses very short.\n        "}, {'role': 'user', 'content': 'User Query: Hello Joe, my cat is coming from yesterday, can you help me?'}], 'model': 'gpt-3.5-turbo', 'max_tokens': 400, 'temperature': 0.7}}
2024-10-04 10:29:52.353 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-10-04 10:29:52.353 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-04 10:29:52.413 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000297A450BE00>
2024-10-04 10:29:52.413 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002979D598C50> server_hostname='api.openai.com' timeout=5.0
2024-10-04 10:29:52.440 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000297A414E270>
2024-10-04 10:29:52.440 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-04 10:29:52.440 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-04 10:29:52.440 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-04 10:29:52.440 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-04 10:29:52.441 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-04 10:29:53.181 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 05:29:53 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'nextweb-yrx64b'), (b'openai-processing-ms', b'297'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'4000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'3999422'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_19b69f5c638cfbdfb4eb1d7f26a4af5a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=J_rIMz.vukTrThVMOpLhWvwS.Asl9VvB3k.DrNLTNbI-1728019793-1.0.1.1-E4mKrHiFvCojCEZCV4ODqTpPx5gr2bmvjWzEVrWQma1sxamL39Y69Ug8xrWvuWWgR3cFFzSv8MLL2BX7dFmAag; path=/; expires=Fri, 04-Oct-24 05:59:53 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=LnEid1kA6wITSzFI4Lwd1G0Dd1GIV6Kkstas2w7j574-1728019793153-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd2c6d6ac6bc601-KHI'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-04 10:29:53.182 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-04 10:29:53.182 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-04 10:29:53.182 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-04 10:29:53.182 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-04 10:29:53.182 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-04 10:29:53.182 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Fri, 04 Oct 2024 05:29:53 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'nextweb-yrx64b'), ('openai-processing-ms', '297'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('x-ratelimit-limit-requests', '5000'), ('x-ratelimit-limit-tokens', '4000000'), ('x-ratelimit-remaining-requests', '4999'), ('x-ratelimit-remaining-tokens', '3999422'), ('x-ratelimit-reset-requests', '12ms'), ('x-ratelimit-reset-tokens', '8ms'), ('x-request-id', 'req_19b69f5c638cfbdfb4eb1d7f26a4af5a'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=J_rIMz.vukTrThVMOpLhWvwS.Asl9VvB3k.DrNLTNbI-1728019793-1.0.1.1-E4mKrHiFvCojCEZCV4ODqTpPx5gr2bmvjWzEVrWQma1sxamL39Y69Ug8xrWvuWWgR3cFFzSv8MLL2BX7dFmAag; path=/; expires=Fri, 04-Oct-24 05:59:53 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=LnEid1kA6wITSzFI4Lwd1G0Dd1GIV6Kkstas2w7j574-1728019793153-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8cd2c6d6ac6bc601-KHI'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2024-10-04 10:29:53.183 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_19b69f5c638cfbdfb4eb1d7f26a4af5a
2024-10-04 10:29:54.341 - RealTimeSTT: root - INFO - Setting listen time
2024-10-04 10:29:54.341 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-04 10:29:54.341 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-04 10:30:04.585 - RealTimeSTT: root - INFO - voice activity detected
2024-10-04 10:30:04.585 - RealTimeSTT: root - INFO - recording started
2024-10-04 10:30:04.585 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-04 10:30:04.586 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-04 10:30:09.187 - RealTimeSTT: root - INFO - recording stopped
2024-10-04 10:30:09.187 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-04 10:30:09.189 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-04 10:30:09.190 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-04 10:30:09.190 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-04 10:30:09.205 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-04 10:30:09.247 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-04 10:30:09.427 - RealTimeSTT: root - DEBUG - Model tiny.en completed transcription in 0.24 seconds
2024-10-04 10:30:09.429 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a medical doctor providing consultations.'}, {'role': 'system', 'content': "\n        You are a medical doctor providing online consultations. Your task is to respond to users' health-related queries. \n        First, ask the user to provide essential details such as their name, age, specific symptoms, and duration of the issue. \n        Be mindful that the user's query may be converted from speech to text, so their input might have informal phrasing, errors, or lack punctuation. \n        After gathering these details, give a clear and thoughtful medical response based on the information provided.\n        Keep your responses very short.\n        "}, {'role': 'assistant', 'content': "Sure, I'd be happy to help. To assist you better, could you please provide more information about your cat's symptoms and any changes in behavior?"}, {'role': 'user', 'content': 'User Query: Yes, she is coming from the last 3 days and having some.'}], 'model': 'gpt-3.5-turbo', 'max_tokens': 400, 'temperature': 0.7}}
2024-10-04 10:30:09.429 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-10-04 10:30:09.429 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-04 10:30:09.429 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-04 10:30:09.429 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-04 10:30:09.466 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000297A451BBC0>
2024-10-04 10:30:09.466 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002979D598C50> server_hostname='api.openai.com' timeout=5.0
2024-10-04 10:30:09.485 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000297A451BBF0>
2024-10-04 10:30:09.485 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-04 10:30:09.485 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-04 10:30:09.485 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-04 10:30:09.485 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-04 10:30:09.485 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-04 10:30:09.705 - RealTimeSTT: root - INFO - voice activity detected
2024-10-04 10:30:09.705 - RealTimeSTT: root - INFO - recording started
2024-10-04 10:30:09.705 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'recording'
2024-10-04 10:30:10.424 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 05:30:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'nextweb-yrx64b'), (b'openai-processing-ms', b'483'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'4000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'3999386'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'9ms'), (b'x-request-id', b'req_ade40bd74d02b743a059096ae598a546'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd2c74138fec615-KHI'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-04 10:30:10.425 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-04 10:30:10.425 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-04 10:30:10.426 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-04 10:30:10.426 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-04 10:30:10.427 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-04 10:30:10.427 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 04 Oct 2024 05:30:10 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'nextweb-yrx64b', 'openai-processing-ms': '483', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '4000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '3999386', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '9ms', 'x-request-id': 'req_ade40bd74d02b743a059096ae598a546', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd2c74138fec615-KHI', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-04 10:30:10.427 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_ade40bd74d02b743a059096ae598a546
2024-10-04 10:30:12.419 - RealTimeSTT: root - INFO - Setting listen time
2024-10-04 10:30:12.419 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-04 10:30:13.158 - RealTimeSTT: root - INFO - recording stopped
2024-10-04 10:30:13.158 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-04 10:30:13.159 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-04 10:30:13.159 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-04 10:30:13.159 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-04 10:30:13.177 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-04 10:30:13.219 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-04 10:30:13.378 - RealTimeSTT: root - DEBUG - Model tiny.en completed transcription in 0.22 seconds
2024-10-04 10:30:13.380 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a medical doctor providing consultations.'}, {'role': 'system', 'content': "\n        You are a medical doctor providing online consultations. Your task is to respond to users' health-related queries. \n        First, ask the user to provide essential details such as their name, age, specific symptoms, and duration of the issue. \n        Be mindful that the user's query may be converted from speech to text, so their input might have informal phrasing, errors, or lack punctuation. \n        After gathering these details, give a clear and thoughtful medical response based on the information provided.\n        Keep your responses very short.\n        "}, {'role': 'assistant', 'content': "Sure, I'd be happy to help. To assist you better, could you please provide more information about your cat's symptoms and any changes in behavior?"}, {'role': 'assistant', 'content': 'I understand that your cat has been showing symptoms for the past 3 days. To better assist you, could you please provide more details about the specific symptoms your cat is experiencing?'}, {'role': 'user', 'content': 'User Query: Ah feeding some pain.'}], 'model': 'gpt-3.5-turbo', 'max_tokens': 400, 'temperature': 0.7}}
2024-10-04 10:30:13.380 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-10-04 10:30:13.380 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-04 10:30:13.380 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-04 10:30:13.380 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-04 10:30:13.380 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-04 10:30:13.380 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-04 10:30:14.302 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 05:30:14 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'nextweb-yrx64b'), (b'openai-processing-ms', b'476'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'4000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'3999346'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'9ms'), (b'x-request-id', b'req_ebd3c54f1a6aa65638633d1cf83a0bc7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd2c7598ec8c615-KHI'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-10-04 10:30:14.303 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-04 10:30:14.303 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-04 10:30:14.304 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-04 10:30:14.304 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-04 10:30:14.305 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-04 10:30:14.305 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 04 Oct 2024 05:30:14 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'nextweb-yrx64b', 'openai-processing-ms': '476', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '4000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '3999346', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '9ms', 'x-request-id': 'req_ebd3c54f1a6aa65638633d1cf83a0bc7', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd2c7598ec8c615-KHI', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-10-04 10:30:14.305 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_ebd3c54f1a6aa65638633d1cf83a0bc7
2024-10-04 10:30:15.974 - RealTimeSTT: root - INFO - Setting listen time
2024-10-04 10:30:15.974 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-04 10:30:15.974 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-04 10:30:25.887 - RealTimeSTT: root - INFO - voice activity detected
2024-10-04 10:30:25.888 - RealTimeSTT: root - INFO - recording started
2024-10-04 10:30:25.888 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-04 10:30:25.888 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-04 10:30:27.106 - RealTimeSTT: root - INFO - recording stopped
2024-10-04 10:30:27.107 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-04 10:30:27.107 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-04 10:30:27.108 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-04 10:30:27.108 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-04 10:30:27.121 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-04 10:30:27.167 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-04 10:30:27.327 - RealTimeSTT: root - DEBUG - Model tiny.en completed transcription in 0.22 seconds
2024-10-04 10:30:27.329 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a medical doctor providing consultations.'}, {'role': 'system', 'content': "\n        You are a medical doctor providing online consultations. Your task is to respond to users' health-related queries. \n        First, ask the user to provide essential details such as their name, age, specific symptoms, and duration of the issue. \n        Be mindful that the user's query may be converted from speech to text, so their input might have informal phrasing, errors, or lack punctuation. \n        After gathering these details, give a clear and thoughtful medical response based on the information provided.\n        Keep your responses very short.\n        "}, {'role': 'assistant', 'content': "Sure, I'd be happy to help. To assist you better, could you please provide more information about your cat's symptoms and any changes in behavior?"}, {'role': 'assistant', 'content': 'I understand that your cat has been showing symptoms for the past 3 days. To better assist you, could you please provide more details about the specific symptoms your cat is experiencing?'}, {'role': 'assistant', 'content': 'It sounds like you may be experiencing some pain. Can you please provide more details about the location and nature of your pain, as well as any other associated symptoms?'}, {'role': 'user', 'content': 'User Query: '}], 'model': 'gpt-3.5-turbo', 'max_tokens': 400, 'temperature': 0.7}}
2024-10-04 10:30:27.329 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-10-04 10:30:27.329 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-04 10:30:27.329 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-04 10:30:27.329 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-04 10:30:27.493 - RealTimeSTT: root - INFO - voice activity detected
2024-10-04 10:30:27.493 - RealTimeSTT: root - INFO - recording started
2024-10-04 10:30:27.494 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'recording'
2024-10-04 10:30:27.520 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000297A4526B40>
2024-10-04 10:30:27.520 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002979D598C50> server_hostname='api.openai.com' timeout=5.0
2024-10-04 10:30:27.673 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002979B6C99D0>
2024-10-04 10:30:27.674 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-04 10:30:27.675 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-04 10:30:27.675 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-04 10:30:27.675 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-04 10:30:27.675 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-04 10:30:28.441 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 05:30:28 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'nextweb-yrx64b'), (b'openai-processing-ms', b'303'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'4000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'3999309'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'10ms'), (b'x-request-id', b'req_1bcb16023b90060440cf0342eaa05e4a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd2c7b34e559eb3-CDG'), (b'Content-Encoding', b'gzip')])
2024-10-04 10:30:28.442 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-04 10:30:28.442 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-04 10:30:28.443 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-04 10:30:28.443 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-04 10:30:28.443 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-04 10:30:28.443 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 04 Oct 2024 05:30:28 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'nextweb-yrx64b', 'openai-processing-ms': '303', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '4000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '3999309', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '10ms', 'x-request-id': 'req_1bcb16023b90060440cf0342eaa05e4a', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd2c7b34e559eb3-CDG', 'content-encoding': 'gzip'})
2024-10-04 10:30:28.443 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_1bcb16023b90060440cf0342eaa05e4a
2024-10-04 10:30:29.668 - RealTimeSTT: root - INFO - Setting listen time
2024-10-04 10:30:29.668 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-04 10:30:30.753 - RealTimeSTT: root - INFO - recording stopped
2024-10-04 10:30:30.753 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-04 10:30:30.754 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-04 10:30:30.754 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-04 10:30:30.754 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-04 10:30:30.755 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-04 10:30:30.824 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-04 10:30:30.851 - RealTimeSTT: root - DEBUG - Model tiny.en completed transcription in 0.10 seconds
2024-10-04 10:30:30.853 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a medical doctor providing consultations.'}, {'role': 'system', 'content': "\n        You are a medical doctor providing online consultations. Your task is to respond to users' health-related queries. \n        First, ask the user to provide essential details such as their name, age, specific symptoms, and duration of the issue. \n        Be mindful that the user's query may be converted from speech to text, so their input might have informal phrasing, errors, or lack punctuation. \n        After gathering these details, give a clear and thoughtful medical response based on the information provided.\n        Keep your responses very short.\n        "}, {'role': 'assistant', 'content': "Sure, I'd be happy to help. To assist you better, could you please provide more information about your cat's symptoms and any changes in behavior?"}, {'role': 'assistant', 'content': 'I understand that your cat has been showing symptoms for the past 3 days. To better assist you, could you please provide more details about the specific symptoms your cat is experiencing?'}, {'role': 'assistant', 'content': 'It sounds like you may be experiencing some pain. Can you please provide more details about the location and nature of your pain, as well as any other associated symptoms?'}, {'role': 'assistant', 'content': "I'm here to help with any health-related questions you may have. Please feel free to share your concerns or symptoms with me."}, {'role': 'user', 'content': 'User Query: She may have feeling some pounces or...'}], 'model': 'gpt-3.5-turbo', 'max_tokens': 400, 'temperature': 0.7}}
2024-10-04 10:30:30.853 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-10-04 10:30:30.853 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-04 10:30:30.854 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-04 10:30:30.854 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-04 10:30:30.854 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-04 10:30:30.854 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-04 10:30:32.322 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 05:30:32 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'nextweb-yrx64b'), (b'openai-processing-ms', b'971'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'4000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'3999267'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'10ms'), (b'x-request-id', b'req_ec882f15e519bd18bd4404af010fca33'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd2c7c71e7c9eb3-CDG'), (b'Content-Encoding', b'gzip')])
2024-10-04 10:30:32.322 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-04 10:30:32.323 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-04 10:30:32.323 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-04 10:30:32.324 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-04 10:30:32.324 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-04 10:30:32.324 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 04 Oct 2024 05:30:32 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'nextweb-yrx64b', 'openai-processing-ms': '971', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '4000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '3999267', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '10ms', 'x-request-id': 'req_ec882f15e519bd18bd4404af010fca33', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd2c7c71e7c9eb3-CDG', 'content-encoding': 'gzip'})
2024-10-04 10:30:32.324 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_ec882f15e519bd18bd4404af010fca33
2024-10-04 10:30:33.052 - RealTimeSTT: root - INFO - Setting listen time
2024-10-04 10:30:33.052 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-04 10:30:33.052 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-04 10:30:37.672 - RealTimeSTT: root - INFO - voice activity detected
2024-10-04 10:30:37.672 - RealTimeSTT: root - INFO - recording started
2024-10-04 10:30:37.673 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-04 10:30:37.673 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-04 10:30:49.507 - RealTimeSTT: root - INFO - recording stopped
2024-10-04 10:30:49.508 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-04 10:30:49.509 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-04 10:30:49.509 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-04 10:30:49.510 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-04 10:30:49.514 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-04 10:30:49.567 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-04 10:30:49.761 - RealTimeSTT: root - INFO - voice activity detected
2024-10-04 10:30:49.761 - RealTimeSTT: root - INFO - recording started
2024-10-04 10:30:49.761 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'recording'
2024-10-04 10:30:50.195 - RealTimeSTT: root - INFO - State changed from 'recording' to 'inactive'
2024-10-04 10:30:50.195 - RealTimeSTT: root - DEBUG - Model tiny.en completed transcription in 0.68 seconds
2024-10-04 10:30:50.198 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a medical doctor providing consultations.'}, {'role': 'system', 'content': "\n        You are a medical doctor providing online consultations. Your task is to respond to users' health-related queries. \n        First, ask the user to provide essential details such as their name, age, specific symptoms, and duration of the issue. \n        Be mindful that the user's query may be converted from speech to text, so their input might have informal phrasing, errors, or lack punctuation. \n        After gathering these details, give a clear and thoughtful medical response based on the information provided.\n        Keep your responses very short.\n        "}, {'role': 'assistant', 'content': "Sure, I'd be happy to help. To assist you better, could you please provide more information about your cat's symptoms and any changes in behavior?"}, {'role': 'assistant', 'content': 'I understand that your cat has been showing symptoms for the past 3 days. To better assist you, could you please provide more details about the specific symptoms your cat is experiencing?'}, {'role': 'assistant', 'content': 'It sounds like you may be experiencing some pain. Can you please provide more details about the location and nature of your pain, as well as any other associated symptoms?'}, {'role': 'assistant', 'content': "I'm here to help with any health-related questions you may have. Please feel free to share your concerns or symptoms with me."}, {'role': 'assistant', 'content': "It seems like your cat may be experiencing some discomfort or pain. It's important to monitor her closely for any changes in behavior, appetite, or litter box habits. If the symptoms persist or worsen, I recommend consulting with a veterinarian for a proper evaluation and treatment."}, {'role': 'user', 'content': 'User Query: '}], 'model': 'gpt-3.5-turbo', 'max_tokens': 400, 'temperature': 0.7}}
2024-10-04 10:30:50.198 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-10-04 10:30:50.198 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-04 10:30:50.198 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-04 10:30:50.198 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-04 10:30:50.356 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000297A42CA150>
2024-10-04 10:30:50.356 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002979D598C50> server_hostname='api.openai.com' timeout=5.0
2024-10-04 10:30:50.502 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000297A453F440>
2024-10-04 10:30:50.502 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-04 10:30:50.502 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-04 10:30:50.503 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-04 10:30:50.503 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-04 10:30:50.503 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-04 10:30:51.316 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 05:30:51 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'nextweb-yrx64b'), (b'openai-processing-ms', b'369'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'4000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'3999204'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'11ms'), (b'x-request-id', b'req_61091793d64c44c325e6700b0f059ad8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd2c841efe1bb1c-CDG'), (b'Content-Encoding', b'gzip')])
2024-10-04 10:30:51.317 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-04 10:30:51.317 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-04 10:30:51.318 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-04 10:30:51.318 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-04 10:30:51.318 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-04 10:30:51.318 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 04 Oct 2024 05:30:51 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'nextweb-yrx64b', 'openai-processing-ms': '369', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '4000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '3999204', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '11ms', 'x-request-id': 'req_61091793d64c44c325e6700b0f059ad8', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd2c841efe1bb1c-CDG', 'content-encoding': 'gzip'})
2024-10-04 10:30:51.318 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_61091793d64c44c325e6700b0f059ad8
2024-10-04 10:30:51.671 - RealTimeSTT: root - INFO - Setting listen time
2024-10-04 10:30:51.671 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-04 10:30:55.967 - RealTimeSTT: root - INFO - recording stopped
2024-10-04 10:30:55.968 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-04 10:30:55.968 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-04 10:30:55.969 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-04 10:30:55.969 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-04 10:30:55.984 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-04 10:30:56.037 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-04 10:30:56.291 - RealTimeSTT: root - DEBUG - Model tiny.en completed transcription in 0.32 seconds
2024-10-04 10:30:56.294 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a medical doctor providing consultations.'}, {'role': 'system', 'content': "\n        You are a medical doctor providing online consultations. Your task is to respond to users' health-related queries. \n        First, ask the user to provide essential details such as their name, age, specific symptoms, and duration of the issue. \n        Be mindful that the user's query may be converted from speech to text, so their input might have informal phrasing, errors, or lack punctuation. \n        After gathering these details, give a clear and thoughtful medical response based on the information provided.\n        Keep your responses very short.\n        "}, {'role': 'assistant', 'content': "Sure, I'd be happy to help. To assist you better, could you please provide more information about your cat's symptoms and any changes in behavior?"}, {'role': 'assistant', 'content': 'I understand that your cat has been showing symptoms for the past 3 days. To better assist you, could you please provide more details about the specific symptoms your cat is experiencing?'}, {'role': 'assistant', 'content': 'It sounds like you may be experiencing some pain. Can you please provide more details about the location and nature of your pain, as well as any other associated symptoms?'}, {'role': 'assistant', 'content': "I'm here to help with any health-related questions you may have. Please feel free to share your concerns or symptoms with me."}, {'role': 'assistant', 'content': "It seems like your cat may be experiencing some discomfort or pain. It's important to monitor her closely for any changes in behavior, appetite, or litter box habits. If the symptoms persist or worsen, I recommend consulting with a veterinarian for a proper evaluation and treatment."}, {'role': 'assistant', 'content': "I see that you haven't provided any details yet. Please feel free to share your health concerns or symptoms with me so I can assist you better."}, {'role': 'user', 'content': 'User Query: And I think she will die soon. I see it. Absolutely, I just get to know her. No, no, listen to me.'}], 'model': 'gpt-3.5-turbo', 'max_tokens': 400, 'temperature': 0.7}}
2024-10-04 10:30:56.296 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-10-04 10:30:56.296 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-04 10:30:56.296 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-04 10:30:56.296 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-04 10:30:56.296 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-04 10:30:56.296 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-04 10:30:57.370 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 05:30:57 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'nextweb-yrx64b'), (b'openai-processing-ms', b'629'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'4000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'3999143'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'12ms'), (b'x-request-id', b'req_22b4e75f1eae00f033d8b2ca33a6883e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd2c86628edbb1c-CDG'), (b'Content-Encoding', b'gzip')])
2024-10-04 10:30:57.371 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-04 10:30:57.371 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-04 10:30:57.372 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-04 10:30:57.372 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-04 10:30:57.372 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-04 10:30:57.372 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 04 Oct 2024 05:30:57 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'nextweb-yrx64b', 'openai-processing-ms': '629', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '4000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '3999143', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '12ms', 'x-request-id': 'req_22b4e75f1eae00f033d8b2ca33a6883e', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd2c86628edbb1c-CDG', 'content-encoding': 'gzip'})
2024-10-04 10:30:57.372 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_22b4e75f1eae00f033d8b2ca33a6883e
2024-10-04 10:30:57.633 - RealTimeSTT: root - INFO - voice activity detected
2024-10-04 10:30:57.633 - RealTimeSTT: root - INFO - recording started
2024-10-04 10:30:57.633 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'recording'
2024-10-04 10:30:58.020 - RealTimeSTT: root - INFO - Setting listen time
2024-10-04 10:30:58.020 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-04 10:31:06.919 - RealTimeSTT: root - INFO - recording stopped
2024-10-04 10:31:06.920 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-04 10:31:06.920 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-04 10:31:06.921 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-04 10:31:06.921 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-04 10:31:06.937 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-04 10:31:06.979 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-04 10:31:07.040 - RealTimeSTT: root - INFO - voice activity detected
2024-10-04 10:31:07.040 - RealTimeSTT: root - INFO - recording started
2024-10-04 10:31:07.040 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'recording'
2024-10-04 10:31:07.240 - RealTimeSTT: root - INFO - State changed from 'recording' to 'inactive'
2024-10-04 10:31:07.240 - RealTimeSTT: root - DEBUG - Model tiny.en completed transcription in 0.32 seconds
2024-10-04 10:31:07.244 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a medical doctor providing consultations.'}, {'role': 'system', 'content': "\n        You are a medical doctor providing online consultations. Your task is to respond to users' health-related queries. \n        First, ask the user to provide essential details such as their name, age, specific symptoms, and duration of the issue. \n        Be mindful that the user's query may be converted from speech to text, so their input might have informal phrasing, errors, or lack punctuation. \n        After gathering these details, give a clear and thoughtful medical response based on the information provided.\n        Keep your responses very short.\n        "}, {'role': 'assistant', 'content': "Sure, I'd be happy to help. To assist you better, could you please provide more information about your cat's symptoms and any changes in behavior?"}, {'role': 'assistant', 'content': 'I understand that your cat has been showing symptoms for the past 3 days. To better assist you, could you please provide more details about the specific symptoms your cat is experiencing?'}, {'role': 'assistant', 'content': 'It sounds like you may be experiencing some pain. Can you please provide more details about the location and nature of your pain, as well as any other associated symptoms?'}, {'role': 'assistant', 'content': "I'm here to help with any health-related questions you may have. Please feel free to share your concerns or symptoms with me."}, {'role': 'assistant', 'content': "It seems like your cat may be experiencing some discomfort or pain. It's important to monitor her closely for any changes in behavior, appetite, or litter box habits. If the symptoms persist or worsen, I recommend consulting with a veterinarian for a proper evaluation and treatment."}, {'role': 'assistant', 'content': "I see that you haven't provided any details yet. Please feel free to share your health concerns or symptoms with me so I can assist you better."}, {'role': 'assistant', 'content': "It sounds like you are very concerned about your cat's health. It's important to stay calm and observe her closely for any changes in behavior or symptoms. If you notice any alarming signs, such as difficulty breathing, severe lethargy, or loss of consciousness, it's crucial to seek immediate veterinary care."}, {'role': 'user', 'content': 'User Query: So it sounds like you can actually see what we have in my chair. Interruptive head-up, woman is compared to here. Today, we are going to go back to the hospital and we are going to go back to the hospital.'}], 'model': 'gpt-3.5-turbo', 'max_tokens': 400, 'temperature': 0.7}}
2024-10-04 10:31:07.244 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-10-04 10:31:07.244 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-04 10:31:07.244 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-04 10:31:07.244 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-04 10:31:07.398 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000297A45E2660>
2024-10-04 10:31:07.398 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002979D598C50> server_hostname='api.openai.com' timeout=5.0
2024-10-04 10:31:07.543 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000297A453F500>
2024-10-04 10:31:07.544 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-04 10:31:07.544 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-04 10:31:07.544 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-04 10:31:07.544 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-04 10:31:07.544 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-04 10:31:08.461 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 05:31:08 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'nextweb-yrx64b'), (b'openai-processing-ms', b'491'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'4000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'3999038'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'14ms'), (b'x-request-id', b'req_775f17e3b357054ef154eec93723ae3b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd2c8ac68753ccf-CDG'), (b'Content-Encoding', b'gzip')])
2024-10-04 10:31:08.462 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-04 10:31:08.462 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-04 10:31:08.463 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-04 10:31:08.463 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-04 10:31:08.463 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-04 10:31:08.463 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 04 Oct 2024 05:31:08 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'nextweb-yrx64b', 'openai-processing-ms': '491', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '4000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '3999038', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '14ms', 'x-request-id': 'req_775f17e3b357054ef154eec93723ae3b', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd2c8ac68753ccf-CDG', 'content-encoding': 'gzip'})
2024-10-04 10:31:08.463 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_775f17e3b357054ef154eec93723ae3b
2024-10-04 10:31:08.838 - RealTimeSTT: root - INFO - Setting listen time
2024-10-04 10:31:08.839 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-04 10:31:15.685 - RealTimeSTT: root - INFO - recording stopped
2024-10-04 10:31:15.686 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-04 10:31:15.686 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-04 10:31:15.686 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-04 10:31:15.687 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-04 10:31:15.688 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-04 10:31:15.745 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-04 10:31:16.592 - RealTimeSTT: root - DEBUG - Model tiny.en completed transcription in 0.90 seconds
2024-10-04 10:31:16.596 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a medical doctor providing consultations.'}, {'role': 'system', 'content': "\n        You are a medical doctor providing online consultations. Your task is to respond to users' health-related queries. \n        First, ask the user to provide essential details such as their name, age, specific symptoms, and duration of the issue. \n        Be mindful that the user's query may be converted from speech to text, so their input might have informal phrasing, errors, or lack punctuation. \n        After gathering these details, give a clear and thoughtful medical response based on the information provided.\n        Keep your responses very short.\n        "}, {'role': 'assistant', 'content': "Sure, I'd be happy to help. To assist you better, could you please provide more information about your cat's symptoms and any changes in behavior?"}, {'role': 'assistant', 'content': 'I understand that your cat has been showing symptoms for the past 3 days. To better assist you, could you please provide more details about the specific symptoms your cat is experiencing?'}, {'role': 'assistant', 'content': 'It sounds like you may be experiencing some pain. Can you please provide more details about the location and nature of your pain, as well as any other associated symptoms?'}, {'role': 'assistant', 'content': "I'm here to help with any health-related questions you may have. Please feel free to share your concerns or symptoms with me."}, {'role': 'assistant', 'content': "It seems like your cat may be experiencing some discomfort or pain. It's important to monitor her closely for any changes in behavior, appetite, or litter box habits. If the symptoms persist or worsen, I recommend consulting with a veterinarian for a proper evaluation and treatment."}, {'role': 'assistant', 'content': "I see that you haven't provided any details yet. Please feel free to share your health concerns or symptoms with me so I can assist you better."}, {'role': 'assistant', 'content': "It sounds like you are very concerned about your cat's health. It's important to stay calm and observe her closely for any changes in behavior or symptoms. If you notice any alarming signs, such as difficulty breathing, severe lethargy, or loss of consciousness, it's crucial to seek immediate veterinary care."}, {'role': 'assistant', 'content': 'It seems like there may have been a misunderstanding in the information provided. If you could please clarify your concerns or symptoms, I would be happy to assist you.'}, {'role': 'user', 'content': 'User Query: In this case, I am trying to do something with you. Listen to me, you motherfucker.'}], 'model': 'gpt-3.5-turbo', 'max_tokens': 400, 'temperature': 0.7}}
2024-10-04 10:31:16.596 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-10-04 10:31:16.596 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-04 10:31:16.596 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-04 10:31:16.596 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-04 10:31:16.752 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000297A45E30E0>
2024-10-04 10:31:16.753 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002979D598C50> server_hostname='api.openai.com' timeout=5.0
2024-10-04 10:31:16.905 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000297A453FF20>
2024-10-04 10:31:16.905 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-04 10:31:16.906 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-04 10:31:16.906 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-04 10:31:16.906 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-04 10:31:16.906 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-04 10:31:17.762 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 05:31:17 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'nextweb-yrx64b'), (b'openai-processing-ms', b'401'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'4000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'3999025'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'14ms'), (b'x-request-id', b'req_00efe0dee014c26947fa7590d00a3771'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd2c8e6ff4f9e57-CDG'), (b'Content-Encoding', b'gzip')])
2024-10-04 10:31:17.763 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-04 10:31:17.763 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-04 10:31:17.764 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-04 10:31:17.765 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-04 10:31:17.765 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-04 10:31:17.765 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 04 Oct 2024 05:31:17 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'nextweb-yrx64b', 'openai-processing-ms': '401', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '4000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '3999025', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '14ms', 'x-request-id': 'req_00efe0dee014c26947fa7590d00a3771', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd2c8e6ff4f9e57-CDG', 'content-encoding': 'gzip'})
2024-10-04 10:31:17.765 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_00efe0dee014c26947fa7590d00a3771
2024-10-04 10:31:17.991 - RealTimeSTT: root - INFO - voice activity detected
2024-10-04 10:31:17.991 - RealTimeSTT: root - INFO - recording started
2024-10-04 10:31:17.991 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'recording'
2024-10-04 10:31:18.177 - RealTimeSTT: root - INFO - Setting listen time
2024-10-04 10:31:18.177 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-04 10:31:20.866 - RealTimeSTT: root - INFO - recording stopped
2024-10-04 10:31:20.867 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-04 10:31:20.867 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-04 10:31:20.867 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-04 10:31:20.867 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-04 10:31:20.877 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-04 10:31:20.927 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-04 10:31:21.357 - RealTimeSTT: root - DEBUG - Model tiny.en completed transcription in 0.49 seconds
2024-10-04 10:31:21.360 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a medical doctor providing consultations.'}, {'role': 'system', 'content': "\n        You are a medical doctor providing online consultations. Your task is to respond to users' health-related queries. \n        First, ask the user to provide essential details such as their name, age, specific symptoms, and duration of the issue. \n        Be mindful that the user's query may be converted from speech to text, so their input might have informal phrasing, errors, or lack punctuation. \n        After gathering these details, give a clear and thoughtful medical response based on the information provided.\n        Keep your responses very short.\n        "}, {'role': 'assistant', 'content': "Sure, I'd be happy to help. To assist you better, could you please provide more information about your cat's symptoms and any changes in behavior?"}, {'role': 'assistant', 'content': 'I understand that your cat has been showing symptoms for the past 3 days. To better assist you, could you please provide more details about the specific symptoms your cat is experiencing?'}, {'role': 'assistant', 'content': 'It sounds like you may be experiencing some pain. Can you please provide more details about the location and nature of your pain, as well as any other associated symptoms?'}, {'role': 'assistant', 'content': "I'm here to help with any health-related questions you may have. Please feel free to share your concerns or symptoms with me."}, {'role': 'assistant', 'content': "It seems like your cat may be experiencing some discomfort or pain. It's important to monitor her closely for any changes in behavior, appetite, or litter box habits. If the symptoms persist or worsen, I recommend consulting with a veterinarian for a proper evaluation and treatment."}, {'role': 'assistant', 'content': "I see that you haven't provided any details yet. Please feel free to share your health concerns or symptoms with me so I can assist you better."}, {'role': 'assistant', 'content': "It sounds like you are very concerned about your cat's health. It's important to stay calm and observe her closely for any changes in behavior or symptoms. If you notice any alarming signs, such as difficulty breathing, severe lethargy, or loss of consciousness, it's crucial to seek immediate veterinary care."}, {'role': 'assistant', 'content': 'It seems like there may have been a misunderstanding in the information provided. If you could please clarify your concerns or symptoms, I would be happy to assist you.'}, {'role': 'assistant', 'content': "I'm here to help with any health-related questions or concerns you may have. If you have any symptoms or issues you'd like to discuss, please feel free to share them with me."}, {'role': 'user', 'content': "User Query: They have a new experience. It's very nice. It's very nice."}], 'model': 'gpt-3.5-turbo', 'max_tokens': 400, 'temperature': 0.7}}
2024-10-04 10:31:21.361 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-10-04 10:31:21.361 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-04 10:31:21.361 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-04 10:31:21.361 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-04 10:31:21.361 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-04 10:31:21.361 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-04 10:31:21.761 - RealTimeSTT: root - INFO - voice activity detected
2024-10-04 10:31:21.761 - RealTimeSTT: root - INFO - recording started
2024-10-04 10:31:21.761 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'recording'
2024-10-04 10:31:22.151 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 05:31:22 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'nextweb-yrx64b'), (b'openai-processing-ms', b'336'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'4000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'3998986'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'15ms'), (b'x-request-id', b'req_c7834e78d7478a886cbd2a183c662840'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd2c902ce2b9e57-CDG'), (b'Content-Encoding', b'gzip')])
2024-10-04 10:31:22.152 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-04 10:31:22.152 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-04 10:31:22.153 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-04 10:31:22.153 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-04 10:31:22.153 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-04 10:31:22.153 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 04 Oct 2024 05:31:22 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'nextweb-yrx64b', 'openai-processing-ms': '336', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '4000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '3998986', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '15ms', 'x-request-id': 'req_c7834e78d7478a886cbd2a183c662840', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd2c902ce2b9e57-CDG', 'content-encoding': 'gzip'})
2024-10-04 10:31:22.153 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_c7834e78d7478a886cbd2a183c662840
2024-10-04 10:31:22.692 - RealTimeSTT: root - INFO - Setting listen time
2024-10-04 10:31:22.692 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-04 10:31:23.873 - RealTimeSTT: root - INFO - recording stopped
2024-10-04 10:31:23.873 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-04 10:31:23.875 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-04 10:31:23.875 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-04 10:31:23.875 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-04 10:31:23.892 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-04 10:31:23.944 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-04 10:31:23.957 - RealTimeSTT: root - DEBUG - Model tiny.en completed transcription in 0.08 seconds
2024-10-04 10:31:23.961 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a medical doctor providing consultations.'}, {'role': 'system', 'content': "\n        You are a medical doctor providing online consultations. Your task is to respond to users' health-related queries. \n        First, ask the user to provide essential details such as their name, age, specific symptoms, and duration of the issue. \n        Be mindful that the user's query may be converted from speech to text, so their input might have informal phrasing, errors, or lack punctuation. \n        After gathering these details, give a clear and thoughtful medical response based on the information provided.\n        Keep your responses very short.\n        "}, {'role': 'assistant', 'content': "Sure, I'd be happy to help. To assist you better, could you please provide more information about your cat's symptoms and any changes in behavior?"}, {'role': 'assistant', 'content': 'I understand that your cat has been showing symptoms for the past 3 days. To better assist you, could you please provide more details about the specific symptoms your cat is experiencing?'}, {'role': 'assistant', 'content': 'It sounds like you may be experiencing some pain. Can you please provide more details about the location and nature of your pain, as well as any other associated symptoms?'}, {'role': 'assistant', 'content': "I'm here to help with any health-related questions you may have. Please feel free to share your concerns or symptoms with me."}, {'role': 'assistant', 'content': "It seems like your cat may be experiencing some discomfort or pain. It's important to monitor her closely for any changes in behavior, appetite, or litter box habits. If the symptoms persist or worsen, I recommend consulting with a veterinarian for a proper evaluation and treatment."}, {'role': 'assistant', 'content': "I see that you haven't provided any details yet. Please feel free to share your health concerns or symptoms with me so I can assist you better."}, {'role': 'assistant', 'content': "It sounds like you are very concerned about your cat's health. It's important to stay calm and observe her closely for any changes in behavior or symptoms. If you notice any alarming signs, such as difficulty breathing, severe lethargy, or loss of consciousness, it's crucial to seek immediate veterinary care."}, {'role': 'assistant', 'content': 'It seems like there may have been a misunderstanding in the information provided. If you could please clarify your concerns or symptoms, I would be happy to assist you.'}, {'role': 'assistant', 'content': "I'm here to help with any health-related questions or concerns you may have. If you have any symptoms or issues you'd like to discuss, please feel free to share them with me."}, {'role': 'assistant', 'content': "I'm glad to hear that you have had a positive experience. If you have any health-related questions or concerns in the future, feel free to reach out."}, {'role': 'user', 'content': "User Query: She's dead."}], 'model': 'gpt-3.5-turbo', 'max_tokens': 400, 'temperature': 0.7}}
2024-10-04 10:31:23.961 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-10-04 10:31:23.961 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-04 10:31:23.961 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-04 10:31:23.961 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-04 10:31:23.961 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-04 10:31:23.961 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-04 10:31:24.877 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 05:31:24 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'nextweb-yrx64b'), (b'openai-processing-ms', b'467'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'4000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'3998961'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'15ms'), (b'x-request-id', b'req_8ccdb59b44fc70b39d415fd40eacc201'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd2c9130dfe9e57-CDG'), (b'Content-Encoding', b'gzip')])
2024-10-04 10:31:24.878 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-04 10:31:24.878 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-04 10:31:24.879 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-04 10:31:24.879 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-04 10:31:24.879 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-04 10:31:24.879 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 04 Oct 2024 05:31:24 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'nextweb-yrx64b', 'openai-processing-ms': '467', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '4000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '3998961', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '15ms', 'x-request-id': 'req_8ccdb59b44fc70b39d415fd40eacc201', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd2c9130dfe9e57-CDG', 'content-encoding': 'gzip'})
2024-10-04 10:31:24.880 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_8ccdb59b44fc70b39d415fd40eacc201
2024-10-04 10:31:25.443 - RealTimeSTT: root - INFO - Setting listen time
2024-10-04 10:31:25.443 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-04 10:31:25.443 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-04 10:31:27.266 - RealTimeSTT: root - INFO - voice activity detected
2024-10-04 10:31:27.266 - RealTimeSTT: root - INFO - recording started
2024-10-04 10:31:27.267 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-04 10:31:27.267 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-04 10:31:28.424 - RealTimeSTT: root - INFO - recording stopped
2024-10-04 10:31:28.425 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-04 10:31:28.425 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-04 10:31:28.425 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-04 10:31:28.426 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-04 10:31:28.430 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-04 10:31:28.485 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-04 10:31:28.508 - RealTimeSTT: root - DEBUG - Model tiny.en completed transcription in 0.08 seconds
2024-10-04 10:31:28.511 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a medical doctor providing consultations.'}, {'role': 'system', 'content': "\n        You are a medical doctor providing online consultations. Your task is to respond to users' health-related queries. \n        First, ask the user to provide essential details such as their name, age, specific symptoms, and duration of the issue. \n        Be mindful that the user's query may be converted from speech to text, so their input might have informal phrasing, errors, or lack punctuation. \n        After gathering these details, give a clear and thoughtful medical response based on the information provided.\n        Keep your responses very short.\n        "}, {'role': 'assistant', 'content': "Sure, I'd be happy to help. To assist you better, could you please provide more information about your cat's symptoms and any changes in behavior?"}, {'role': 'assistant', 'content': 'I understand that your cat has been showing symptoms for the past 3 days. To better assist you, could you please provide more details about the specific symptoms your cat is experiencing?'}, {'role': 'assistant', 'content': 'It sounds like you may be experiencing some pain. Can you please provide more details about the location and nature of your pain, as well as any other associated symptoms?'}, {'role': 'assistant', 'content': "I'm here to help with any health-related questions you may have. Please feel free to share your concerns or symptoms with me."}, {'role': 'assistant', 'content': "It seems like your cat may be experiencing some discomfort or pain. It's important to monitor her closely for any changes in behavior, appetite, or litter box habits. If the symptoms persist or worsen, I recommend consulting with a veterinarian for a proper evaluation and treatment."}, {'role': 'assistant', 'content': "I see that you haven't provided any details yet. Please feel free to share your health concerns or symptoms with me so I can assist you better."}, {'role': 'assistant', 'content': "It sounds like you are very concerned about your cat's health. It's important to stay calm and observe her closely for any changes in behavior or symptoms. If you notice any alarming signs, such as difficulty breathing, severe lethargy, or loss of consciousness, it's crucial to seek immediate veterinary care."}, {'role': 'assistant', 'content': 'It seems like there may have been a misunderstanding in the information provided. If you could please clarify your concerns or symptoms, I would be happy to assist you.'}, {'role': 'assistant', 'content': "I'm here to help with any health-related questions or concerns you may have. If you have any symptoms or issues you'd like to discuss, please feel free to share them with me."}, {'role': 'assistant', 'content': "I'm glad to hear that you have had a positive experience. If you have any health-related questions or concerns in the future, feel free to reach out."}, {'role': 'assistant', 'content': "I'm truly sorry to hear about your loss. Losing a pet can be incredibly difficult. If you need support during this time, please don't hesitate to reach out to friends, family, or a support group. Take care."}, {'role': 'user', 'content': 'User Query: To hear about your loss.'}], 'model': 'gpt-3.5-turbo', 'max_tokens': 400, 'temperature': 0.7}}
2024-10-04 10:31:28.512 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-10-04 10:31:28.512 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-04 10:31:28.512 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-04 10:31:28.512 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-04 10:31:28.512 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-04 10:31:28.512 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-04 10:31:28.800 - RealTimeSTT: root - INFO - voice activity detected
2024-10-04 10:31:28.801 - RealTimeSTT: root - INFO - recording started
2024-10-04 10:31:28.801 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'recording'
2024-10-04 10:31:29.292 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 05:31:29 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'nextweb-yrx64b'), (b'openai-processing-ms', b'444'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'4000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'3998904'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'16ms'), (b'x-request-id', b'req_1bfd3ea6b5f02354f778c1bd0971460f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd2c92f7c859e57-CDG'), (b'Content-Encoding', b'gzip')])
2024-10-04 10:31:29.293 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-04 10:31:29.293 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-04 10:31:29.293 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-04 10:31:29.294 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-04 10:31:29.294 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-04 10:31:29.294 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 04 Oct 2024 05:31:29 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'nextweb-yrx64b', 'openai-processing-ms': '444', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '4000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '3998904', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '16ms', 'x-request-id': 'req_1bfd3ea6b5f02354f778c1bd0971460f', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd2c92f7c859e57-CDG', 'content-encoding': 'gzip'})
2024-10-04 10:31:29.294 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_1bfd3ea6b5f02354f778c1bd0971460f
2024-10-04 10:31:29.803 - RealTimeSTT: root - INFO - Setting listen time
2024-10-04 10:31:29.803 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-04 10:31:30.720 - RealTimeSTT: root - INFO - recording stopped
2024-10-04 10:31:30.721 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-04 10:31:30.721 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-04 10:31:30.721 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-04 10:31:30.721 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-04 10:31:30.741 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-04 10:31:30.791 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-04 10:31:30.806 - RealTimeSTT: root - DEBUG - Model tiny.en completed transcription in 0.08 seconds
2024-10-04 10:31:30.810 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a medical doctor providing consultations.'}, {'role': 'system', 'content': "\n        You are a medical doctor providing online consultations. Your task is to respond to users' health-related queries. \n        First, ask the user to provide essential details such as their name, age, specific symptoms, and duration of the issue. \n        Be mindful that the user's query may be converted from speech to text, so their input might have informal phrasing, errors, or lack punctuation. \n        After gathering these details, give a clear and thoughtful medical response based on the information provided.\n        Keep your responses very short.\n        "}, {'role': 'assistant', 'content': "Sure, I'd be happy to help. To assist you better, could you please provide more information about your cat's symptoms and any changes in behavior?"}, {'role': 'assistant', 'content': 'I understand that your cat has been showing symptoms for the past 3 days. To better assist you, could you please provide more details about the specific symptoms your cat is experiencing?'}, {'role': 'assistant', 'content': 'It sounds like you may be experiencing some pain. Can you please provide more details about the location and nature of your pain, as well as any other associated symptoms?'}, {'role': 'assistant', 'content': "I'm here to help with any health-related questions you may have. Please feel free to share your concerns or symptoms with me."}, {'role': 'assistant', 'content': "It seems like your cat may be experiencing some discomfort or pain. It's important to monitor her closely for any changes in behavior, appetite, or litter box habits. If the symptoms persist or worsen, I recommend consulting with a veterinarian for a proper evaluation and treatment."}, {'role': 'assistant', 'content': "I see that you haven't provided any details yet. Please feel free to share your health concerns or symptoms with me so I can assist you better."}, {'role': 'assistant', 'content': "It sounds like you are very concerned about your cat's health. It's important to stay calm and observe her closely for any changes in behavior or symptoms. If you notice any alarming signs, such as difficulty breathing, severe lethargy, or loss of consciousness, it's crucial to seek immediate veterinary care."}, {'role': 'assistant', 'content': 'It seems like there may have been a misunderstanding in the information provided. If you could please clarify your concerns or symptoms, I would be happy to assist you.'}, {'role': 'assistant', 'content': "I'm here to help with any health-related questions or concerns you may have. If you have any symptoms or issues you'd like to discuss, please feel free to share them with me."}, {'role': 'assistant', 'content': "I'm glad to hear that you have had a positive experience. If you have any health-related questions or concerns in the future, feel free to reach out."}, {'role': 'assistant', 'content': "I'm truly sorry to hear about your loss. Losing a pet can be incredibly difficult. If you need support during this time, please don't hesitate to reach out to friends, family, or a support group. Take care."}, {'role': 'assistant', 'content': 'Thank you for your kind words. If you have any health-related questions or concerns, feel free to share them with me.'}, {'role': 'user', 'content': "User Query: I don't care if she's dead or not."}], 'model': 'gpt-3.5-turbo', 'max_tokens': 400, 'temperature': 0.7}}
2024-10-04 10:31:30.812 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-10-04 10:31:30.812 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-04 10:31:30.812 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-04 10:31:30.812 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-04 10:31:30.812 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-04 10:31:30.812 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-04 10:31:31.591 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 05:31:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'nextweb-yrx64b'), (b'openai-processing-ms', b'325'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'4000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'3998872'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'16ms'), (b'x-request-id', b'req_45f8072e7bb9a9b80539833764072ad7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd2c93ddb969e57-CDG'), (b'Content-Encoding', b'gzip')])
2024-10-04 10:31:31.591 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-04 10:31:31.591 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-04 10:31:31.592 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-04 10:31:31.592 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-04 10:31:31.592 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-04 10:31:31.592 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 04 Oct 2024 05:31:31 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'nextweb-yrx64b', 'openai-processing-ms': '325', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '4000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '3998872', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '16ms', 'x-request-id': 'req_45f8072e7bb9a9b80539833764072ad7', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd2c93ddb969e57-CDG', 'content-encoding': 'gzip'})
2024-10-04 10:31:31.592 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_45f8072e7bb9a9b80539833764072ad7
2024-10-04 10:31:31.624 - RealTimeSTT: root - INFO - voice activity detected
2024-10-04 10:31:31.624 - RealTimeSTT: root - INFO - recording started
2024-10-04 10:31:31.624 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'recording'
2024-10-04 10:31:32.036 - RealTimeSTT: root - INFO - Setting listen time
2024-10-04 10:31:32.036 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-04 10:31:34.114 - RealTimeSTT: root - INFO - recording stopped
2024-10-04 10:31:34.114 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-04 10:31:34.114 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-04 10:31:34.114 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-04 10:31:34.114 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-04 10:31:34.133 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-04 10:31:34.184 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-04 10:31:34.200 - RealTimeSTT: root - DEBUG - Model tiny.en completed transcription in 0.09 seconds
2024-10-04 10:31:34.205 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a medical doctor providing consultations.'}, {'role': 'system', 'content': "\n        You are a medical doctor providing online consultations. Your task is to respond to users' health-related queries. \n        First, ask the user to provide essential details such as their name, age, specific symptoms, and duration of the issue. \n        Be mindful that the user's query may be converted from speech to text, so their input might have informal phrasing, errors, or lack punctuation. \n        After gathering these details, give a clear and thoughtful medical response based on the information provided.\n        Keep your responses very short.\n        "}, {'role': 'assistant', 'content': "Sure, I'd be happy to help. To assist you better, could you please provide more information about your cat's symptoms and any changes in behavior?"}, {'role': 'assistant', 'content': 'I understand that your cat has been showing symptoms for the past 3 days. To better assist you, could you please provide more details about the specific symptoms your cat is experiencing?'}, {'role': 'assistant', 'content': 'It sounds like you may be experiencing some pain. Can you please provide more details about the location and nature of your pain, as well as any other associated symptoms?'}, {'role': 'assistant', 'content': "I'm here to help with any health-related questions you may have. Please feel free to share your concerns or symptoms with me."}, {'role': 'assistant', 'content': "It seems like your cat may be experiencing some discomfort or pain. It's important to monitor her closely for any changes in behavior, appetite, or litter box habits. If the symptoms persist or worsen, I recommend consulting with a veterinarian for a proper evaluation and treatment."}, {'role': 'assistant', 'content': "I see that you haven't provided any details yet. Please feel free to share your health concerns or symptoms with me so I can assist you better."}, {'role': 'assistant', 'content': "It sounds like you are very concerned about your cat's health. It's important to stay calm and observe her closely for any changes in behavior or symptoms. If you notice any alarming signs, such as difficulty breathing, severe lethargy, or loss of consciousness, it's crucial to seek immediate veterinary care."}, {'role': 'assistant', 'content': 'It seems like there may have been a misunderstanding in the information provided. If you could please clarify your concerns or symptoms, I would be happy to assist you.'}, {'role': 'assistant', 'content': "I'm here to help with any health-related questions or concerns you may have. If you have any symptoms or issues you'd like to discuss, please feel free to share them with me."}, {'role': 'assistant', 'content': "I'm glad to hear that you have had a positive experience. If you have any health-related questions or concerns in the future, feel free to reach out."}, {'role': 'assistant', 'content': "I'm truly sorry to hear about your loss. Losing a pet can be incredibly difficult. If you need support during this time, please don't hesitate to reach out to friends, family, or a support group. Take care."}, {'role': 'assistant', 'content': 'Thank you for your kind words. If you have any health-related questions or concerns, feel free to share them with me.'}, {'role': 'assistant', 'content': "I'm here to provide medical assistance. If you have any health-related questions or concerns, please feel free to share them with me."}, {'role': 'user', 'content': "User Query: So I'll do this one to provide medical assistance."}], 'model': 'gpt-3.5-turbo', 'max_tokens': 400, 'temperature': 0.7}}
2024-10-04 10:31:34.205 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-10-04 10:31:34.205 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-04 10:31:34.205 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-04 10:31:34.205 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-04 10:31:34.205 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-04 10:31:34.205 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-04 10:31:35.141 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 05:31:35 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'nextweb-yrx64b'), (b'openai-processing-ms', b'517'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'4000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'3998834'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'17ms'), (b'x-request-id', b'req_51be00282ecaaeee004246c8efbd6ba8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd2c9530fd19e57-CDG'), (b'Content-Encoding', b'gzip')])
2024-10-04 10:31:35.142 - RealTimeSTT: httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-10-04 10:31:35.143 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-10-04 10:31:35.143 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_body.complete
2024-10-04 10:31:35.144 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-04 10:31:35.144 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-04 10:31:35.144 - RealTimeSTT: openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 04 Oct 2024 05:31:35 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'nextweb-yrx64b', 'openai-processing-ms': '517', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '4000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '3998834', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '17ms', 'x-request-id': 'req_51be00282ecaaeee004246c8efbd6ba8', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd2c9530fd19e57-CDG', 'content-encoding': 'gzip'})
2024-10-04 10:31:35.144 - RealTimeSTT: openai._base_client - DEBUG - request_id: req_51be00282ecaaeee004246c8efbd6ba8
2024-10-04 10:31:35.590 - RealTimeSTT: root - INFO - Setting listen time
2024-10-04 10:31:35.590 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'listening'
2024-10-04 10:31:35.591 - RealTimeSTT: root - DEBUG - Waiting for recording start
2024-10-04 10:31:37.507 - RealTimeSTT: root - INFO - voice activity detected
2024-10-04 10:31:37.507 - RealTimeSTT: root - INFO - recording started
2024-10-04 10:31:37.507 - RealTimeSTT: root - INFO - State changed from 'listening' to 'recording'
2024-10-04 10:31:37.507 - RealTimeSTT: root - DEBUG - Waiting for recording stop
2024-10-04 10:31:42.504 - RealTimeSTT: root - INFO - recording stopped
2024-10-04 10:31:42.505 - RealTimeSTT: root - INFO - State changed from 'recording' to 'listening'
2024-10-04 10:31:42.506 - RealTimeSTT: root - INFO - State changed from 'listening' to 'inactive'
2024-10-04 10:31:42.506 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'transcribing'
2024-10-04 10:31:42.506 - RealTimeSTT: root - DEBUG - Adding transcription request, no early transcription started
2024-10-04 10:31:42.518 - RealTimeSTT: root - DEBUG - Receive from parent_transcription_pipe after sendiung transcription request, transcribe_count: 1
2024-10-04 10:31:42.566 - RealTimeSTT: root - INFO - State changed from 'transcribing' to 'inactive'
2024-10-04 10:31:42.635 - RealTimeSTT: root - DEBUG - Model tiny.en completed transcription in 0.13 seconds
2024-10-04 10:31:42.640 - RealTimeSTT: openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a medical doctor providing consultations.'}, {'role': 'system', 'content': "\n        You are a medical doctor providing online consultations. Your task is to respond to users' health-related queries. \n        First, ask the user to provide essential details such as their name, age, specific symptoms, and duration of the issue. \n        Be mindful that the user's query may be converted from speech to text, so their input might have informal phrasing, errors, or lack punctuation. \n        After gathering these details, give a clear and thoughtful medical response based on the information provided.\n        Keep your responses very short.\n        "}, {'role': 'assistant', 'content': "Sure, I'd be happy to help. To assist you better, could you please provide more information about your cat's symptoms and any changes in behavior?"}, {'role': 'assistant', 'content': 'I understand that your cat has been showing symptoms for the past 3 days. To better assist you, could you please provide more details about the specific symptoms your cat is experiencing?'}, {'role': 'assistant', 'content': 'It sounds like you may be experiencing some pain. Can you please provide more details about the location and nature of your pain, as well as any other associated symptoms?'}, {'role': 'assistant', 'content': "I'm here to help with any health-related questions you may have. Please feel free to share your concerns or symptoms with me."}, {'role': 'assistant', 'content': "It seems like your cat may be experiencing some discomfort or pain. It's important to monitor her closely for any changes in behavior, appetite, or litter box habits. If the symptoms persist or worsen, I recommend consulting with a veterinarian for a proper evaluation and treatment."}, {'role': 'assistant', 'content': "I see that you haven't provided any details yet. Please feel free to share your health concerns or symptoms with me so I can assist you better."}, {'role': 'assistant', 'content': "It sounds like you are very concerned about your cat's health. It's important to stay calm and observe her closely for any changes in behavior or symptoms. If you notice any alarming signs, such as difficulty breathing, severe lethargy, or loss of consciousness, it's crucial to seek immediate veterinary care."}, {'role': 'assistant', 'content': 'It seems like there may have been a misunderstanding in the information provided. If you could please clarify your concerns or symptoms, I would be happy to assist you.'}, {'role': 'assistant', 'content': "I'm here to help with any health-related questions or concerns you may have. If you have any symptoms or issues you'd like to discuss, please feel free to share them with me."}, {'role': 'assistant', 'content': "I'm glad to hear that you have had a positive experience. If you have any health-related questions or concerns in the future, feel free to reach out."}, {'role': 'assistant', 'content': "I'm truly sorry to hear about your loss. Losing a pet can be incredibly difficult. If you need support during this time, please don't hesitate to reach out to friends, family, or a support group. Take care."}, {'role': 'assistant', 'content': 'Thank you for your kind words. If you have any health-related questions or concerns, feel free to share them with me.'}, {'role': 'assistant', 'content': "I'm here to provide medical assistance. If you have any health-related questions or concerns, please feel free to share them with me."}, {'role': 'assistant', 'content': 'It seems like you are trying to convey that you would like to receive medical assistance. If you have any health-related questions or concerns, please feel free to share them with me.'}, {'role': 'user', 'content': "User Query: We're trying to convey that you would like to Just create a kimazipas every fine one in ballet."}], 'model': 'gpt-3.5-turbo', 'max_tokens': 400, 'temperature': 0.7}}
2024-10-04 10:31:42.640 - RealTimeSTT: openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-10-04 10:31:42.640 - RealTimeSTT: httpcore.connection - DEBUG - close.started
2024-10-04 10:31:42.641 - RealTimeSTT: httpcore.connection - DEBUG - close.complete
2024-10-04 10:31:42.641 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-10-04 10:31:42.699 - RealTimeSTT: httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000297A45FBE90>
2024-10-04 10:31:42.699 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002979D598C50> server_hostname='api.openai.com' timeout=5.0
2024-10-04 10:31:42.724 - RealTimeSTT: httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000297A45FBC20>
2024-10-04 10:31:42.724 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-10-04 10:31:42.724 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_headers.complete
2024-10-04 10:31:42.724 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-10-04 10:31:42.724 - RealTimeSTT: httpcore.http11 - DEBUG - send_request_body.complete
2024-10-04 10:31:42.725 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-10-04 10:31:43.606 - RealTimeSTT: httpcore.http11 - DEBUG - receive_response_headers.failed exception=KeyboardInterrupt()
2024-10-04 10:31:43.641 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.started
2024-10-04 10:31:43.642 - RealTimeSTT: httpcore.http11 - DEBUG - response_closed.complete
2024-10-04 10:31:54.979 - RealTimeSTT: root - INFO - voice activity detected
2024-10-04 10:31:54.979 - RealTimeSTT: root - INFO - recording started
2024-10-04 10:31:54.980 - RealTimeSTT: root - INFO - State changed from 'inactive' to 'recording'
